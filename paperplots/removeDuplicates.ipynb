{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import json\n",
    "import befaas.logentry as le\n",
    "from befaas.fileutil import log_entry_iterator\n",
    "\n",
    "sns.set()\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "dump = \"dumpIoT4.json\"\n",
    "outFile = \"../dumps/uniqueIoT.json\"\n",
    "print(\"Everything is set up.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump dumpIoT4.json ...\n",
      "Iterate over ../dumps/dumpIoT4.json ...\n",
      "(I)  processed 10000 entries\n",
      "(I)  processed 20000 entries\n",
      "(I)  processed 30000 entries\n",
      "(I)  processed 40000 entries\n",
      "(I)  processed 50000 entries\n",
      "(I)  processed 60000 entries\n",
      "(I)  processed 70000 entries\n",
      "(I)  processed 80000 entries\n",
      "(I)  processed 90000 entries\n",
      "(I)  processed 100000 entries\n",
      "(I)  processed 110000 entries\n",
      "(I)  processed 120000 entries\n",
      "(I)  processed 130000 entries\n",
      "(I)  processed 140000 entries\n",
      "(I)  processed 150000 entries\n",
      "(I)  processed 160000 entries\n",
      "(I)  processed 170000 entries\n",
      "(I)  processed 180000 entries\n",
      "(I)  processed 190000 entries\n",
      "(I)  processed 200000 entries\n",
      "(I)  processed 210000 entries\n",
      "(I)  processed 220000 entries\n",
      "(I)  processed 230000 entries\n",
      "(I)  processed 240000 entries\n",
      "(I)  processed 250000 entries\n",
      "(I)  processed 260000 entries\n",
      "(I)  processed 270000 entries\n",
      "(I)  processed 280000 entries\n",
      "(I)  processed 290000 entries\n",
      "(I)  processed 300000 entries\n",
      "(I)  processed 310000 entries\n",
      "(I)  processed 320000 entries\n",
      "(I)  processed 330000 entries\n",
      "(I)  processed 340000 entries\n",
      "(I)  processed 350000 entries\n",
      "(I)  processed 360000 entries\n",
      "(I)  processed 370000 entries\n",
      "(I)  processed 380000 entries\n",
      "(I)  processed 390000 entries\n",
      "(I)  processed 400000 entries\n",
      "(I)  processed 410000 entries\n",
      "(I)  processed 420000 entries\n",
      "(I)  processed 430000 entries\n",
      "(I)  processed 440000 entries\n",
      "(I)  processed 450000 entries\n",
      "(I)  processed 460000 entries\n",
      "(I)  processed 470000 entries\n",
      "(I)  processed 480000 entries\n",
      "(I)  processed 490000 entries\n",
      "(I)  processed 500000 entries\n",
      "(I)  processed 510000 entries\n",
      "(I)  processed 520000 entries\n",
      "(I)  processed 530000 entries\n",
      "(I)  processed 540000 entries\n",
      "(I)  processed 550000 entries\n",
      "(I)  processed 560000 entries\n",
      "(I)  processed 570000 entries\n",
      "(I)  processed 580000 entries\n",
      "(I)  processed 590000 entries\n",
      "(I)  processed 600000 entries\n",
      "(I)  processed 610000 entries\n",
      "(I)  processed 620000 entries\n",
      "(I)  processed 630000 entries\n",
      "Writing to ../dumps/uniqueIoT.json\n",
      "Iterate over ../dumps/dumpIoT4.json ...\n",
      "(II) processed 10000 entries\n",
      "(II) processed 20000 entries\n",
      "(II) processed 30000 entries\n",
      "(II) processed 40000 entries\n",
      "(II) processed 50000 entries\n",
      "(II) processed 60000 entries\n",
      "(II) processed 70000 entries\n",
      "(II) processed 80000 entries\n",
      "(II) processed 90000 entries\n",
      "(II) processed 100000 entries\n",
      "(II) processed 110000 entries\n",
      "(II) processed 120000 entries\n",
      "(II) processed 130000 entries\n",
      "(II) processed 140000 entries\n",
      "(II) processed 150000 entries\n",
      "(II) processed 160000 entries\n",
      "(II) processed 170000 entries\n",
      "(II) processed 180000 entries\n",
      "(II) processed 190000 entries\n",
      "(II) processed 200000 entries\n",
      "(II) processed 210000 entries\n",
      "(II) processed 220000 entries\n",
      "(II) processed 230000 entries\n",
      "(II) processed 240000 entries\n",
      "(II) processed 250000 entries\n",
      "(II) processed 260000 entries\n",
      "(II) processed 270000 entries\n",
      "(II) processed 280000 entries\n",
      "(II) processed 290000 entries\n",
      "(II) processed 300000 entries\n",
      "(II) processed 310000 entries\n",
      "(II) processed 320000 entries\n",
      "(II) processed 330000 entries\n",
      "(II) processed 340000 entries\n",
      "(II) processed 350000 entries\n",
      "(II) processed 360000 entries\n",
      "(II) processed 370000 entries\n",
      "(II) processed 380000 entries\n",
      "(II) processed 390000 entries\n",
      "(II) processed 400000 entries\n",
      "(II) processed 410000 entries\n",
      "(II) processed 420000 entries\n",
      "(II) processed 430000 entries\n",
      "(II) processed 440000 entries\n",
      "(II) processed 450000 entries\n",
      "(II) processed 460000 entries\n",
      "(II) processed 470000 entries\n",
      "(II) processed 480000 entries\n",
      "(II) processed 490000 entries\n",
      "(II) processed 500000 entries\n",
      "(II) processed 510000 entries\n",
      "(II) processed 520000 entries\n",
      "(II) processed 530000 entries\n",
      "(II) processed 540000 entries\n",
      "(II) processed 550000 entries\n",
      "(II) processed 560000 entries\n",
      "(II) processed 570000 entries\n",
      "(II) processed 580000 entries\n",
      "(II) processed 590000 entries\n",
      "(II) processed 600000 entries\n",
      "(II) processed 610000 entries\n",
      "(II) processed 620000 entries\n",
      "(II) processed 630000 entries\n",
      "Found and removed 0 duplicates.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Include dump {dump} ...\")\n",
    "# Count entries to get some progress feedback\n",
    "entries = 0\n",
    "contexts = {}\n",
    "otherUserAgentContextList = []\n",
    "\n",
    "for entry in log_entry_iterator(filepath + dump):\n",
    "    entries = entries + 1\n",
    "    if (entries % 10000 == 0):\n",
    "        print(f\"(I)  processed {entries} entries\")\n",
    "\n",
    "    logentry = le.cast_log_type(entry)\n",
    "    if isinstance(logentry, le.RequestLog):\n",
    "        userAgent = logentry.event['request']['headers']['user-agent']\n",
    "        if not str(userAgent).startswith(\"node-fetch\") | str(userAgent).startswith(\"Artillery\"):\n",
    "            print(f\"Other user agent, will filter: {userAgent}\")\n",
    "            otherUserAgentContextList.append(logentry.context_id)\n",
    "\n",
    "entries = 0\n",
    "duplicates = 0\n",
    "print(f\"Writing to {outFile}\")\n",
    "with open(outFile, \"w\") as jsfile:\n",
    "    jsfile.write(\"[\")\n",
    "    initial = True\n",
    "\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        entryOK = True\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(II) processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        id = logentry.context_id\n",
    "\n",
    "        if id in otherUserAgentContextList:\n",
    "            # Wrong user agent\n",
    "            print(f\"filtered context {id}\")\n",
    "            entryOK = False\n",
    "            continue\n",
    "\n",
    "        # Create context if there isn't one\n",
    "        if not (id in contexts):\n",
    "            contexts[id] = []\n",
    "\n",
    "        for checkEntry in contexts[id]:\n",
    "            if str(checkEntry).strip() == str(entry).strip():\n",
    "                # found duplicate\n",
    "                duplicates += 1\n",
    "                entryOK = False\n",
    "                #print(f\"filtered a duplicate for ctx {id}\")\n",
    "                continue\n",
    "\n",
    "        if (entryOK):\n",
    "            contexts[id].append(entry)\n",
    "            #write entry to file\n",
    "            jsfile.write((\"\" if initial else \",\\n\") + json.dumps(entry))\n",
    "            initial = False\n",
    "\n",
    "    jsfile.write(\"]\")\n",
    "\n",
    "print(f\"Found and removed {duplicates} duplicates.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}