{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import befaas.logentry as le\n",
    "from befaas.fileutil import log_entry_iterator\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "logdumps = [\"dumpAWS.json\",\"dumpGoogle.json\",\"dumpAzure.json\"]\n",
    "oufile = \"../img/functionRuntimesEcomm.pkl\"\n",
    "print(\"Everything is set up.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump dumpAWS.json ...\n",
      "Iterate over ../dumps/dumpAWS.json ...\n",
      "(1/2)  processed 10000 entries\n",
      "(1/2)  processed 20000 entries\n",
      "(1/2)  processed 30000 entries\n",
      "(1/2)  processed 40000 entries\n",
      "(1/2)  processed 50000 entries\n",
      "(1/2)  processed 60000 entries\n",
      "(1/2)  processed 70000 entries\n",
      "(1/2)  processed 80000 entries\n",
      "(1/2)  processed 90000 entries\n",
      "(1/2)  processed 100000 entries\n",
      "(1/2)  processed 110000 entries\n",
      "(1/2)  processed 120000 entries\n",
      "(1/2)  processed 130000 entries\n",
      "(1/2)  processed 140000 entries\n",
      "(1/2)  processed 150000 entries\n",
      "(1/2)  processed 160000 entries\n",
      "(1/2)  processed 170000 entries\n",
      "(1/2)  processed 180000 entries\n",
      "(1/2)  processed 190000 entries\n",
      "(1/2)  processed 200000 entries\n",
      "(1/2)  processed 210000 entries\n",
      "(1/2)  processed 220000 entries\n",
      "(1/2)  processed 230000 entries\n",
      "(1/2)  processed 240000 entries\n",
      "(1/2)  processed 250000 entries\n",
      "(1/2)  processed 260000 entries\n",
      "(1/2)  processed 270000 entries\n",
      "(1/2)  processed 280000 entries\n",
      "(1/2)  processed 290000 entries\n",
      "(1/2)  processed 300000 entries\n",
      "(1/2)  processed 310000 entries\n",
      "(1/2)  processed 320000 entries\n",
      "(1/2)  processed 330000 entries\n",
      "(1/2)  processed 340000 entries\n",
      "(1/2)  processed 350000 entries\n",
      "(1/2)  processed 360000 entries\n",
      "(1/2)  processed 370000 entries\n",
      "(1/2)  processed 380000 entries\n",
      "(1/2)  processed 390000 entries\n",
      "(1/2)  processed 400000 entries\n",
      "(1/2)  processed 410000 entries\n",
      "(1/2)  processed 420000 entries\n",
      "(1/2)  processed 430000 entries\n",
      "(1/2)  processed 440000 entries\n",
      "(1/2)  processed 450000 entries\n",
      "(1/2)  processed 460000 entries\n",
      "(1/2)  processed 470000 entries\n",
      "(1/2)  processed 480000 entries\n",
      "(1/2)  processed 490000 entries\n",
      "(1/2)  processed 500000 entries\n",
      "(1/2)  processed 510000 entries\n",
      "(1/2)  processed 520000 entries\n",
      "(1/2)  processed 530000 entries\n",
      "(1/2)  processed 540000 entries\n",
      "(1/2)  processed 550000 entries\n",
      "(1/2)  processed 560000 entries\n",
      "(1/2)  processed 570000 entries\n",
      "(1/2)  processed 580000 entries\n",
      "(1/2)  processed 590000 entries\n",
      "(1/2)  processed 600000 entries\n",
      "(1/2)  processed 610000 entries\n",
      "(1/2)  processed 620000 entries\n",
      "(1/2)  processed 630000 entries\n",
      "(1/2)  processed 640000 entries\n",
      "(1/2)  processed 650000 entries\n",
      "(1/2)  processed 660000 entries\n",
      "(1/2)  processed 670000 entries\n",
      "(1/2)  processed 680000 entries\n",
      "(1/2)  processed 690000 entries\n",
      "(1/2)  processed 700000 entries\n",
      "(1/2)  processed 710000 entries\n",
      "(1/2)  processed 720000 entries\n",
      "(1/2)  processed 730000 entries\n",
      "(1/2)  processed 740000 entries\n",
      "(1/2)  processed 750000 entries\n",
      "(1/2)  processed 760000 entries\n",
      "Iterate over ../dumps/dumpAWS.json ...\n",
      "(2/2) processed 10000 entries\n",
      "(2/2) processed 20000 entries\n",
      "(2/2) processed 30000 entries\n",
      "(2/2) processed 40000 entries\n",
      "(2/2) processed 50000 entries\n",
      "(2/2) processed 60000 entries\n",
      "(2/2) processed 70000 entries\n",
      "(2/2) processed 80000 entries\n",
      "(2/2) processed 90000 entries\n",
      "(2/2) processed 100000 entries\n",
      "(2/2) processed 110000 entries\n",
      "(2/2) processed 120000 entries\n",
      "(2/2) processed 130000 entries\n",
      "(2/2) processed 140000 entries\n",
      "(2/2) processed 150000 entries\n",
      "(2/2) processed 160000 entries\n",
      "(2/2) processed 170000 entries\n",
      "(2/2) processed 180000 entries\n",
      "(2/2) processed 190000 entries\n",
      "(2/2) processed 200000 entries\n",
      "(2/2) processed 210000 entries\n",
      "(2/2) processed 220000 entries\n",
      "(2/2) processed 230000 entries\n",
      "(2/2) processed 240000 entries\n",
      "(2/2) processed 250000 entries\n",
      "(2/2) processed 260000 entries\n",
      "(2/2) processed 270000 entries\n",
      "(2/2) processed 280000 entries\n",
      "(2/2) processed 290000 entries\n",
      "(2/2) processed 300000 entries\n",
      "(2/2) processed 310000 entries\n",
      "(2/2) processed 320000 entries\n",
      "(2/2) processed 330000 entries\n",
      "(2/2) processed 340000 entries\n",
      "(2/2) processed 350000 entries\n",
      "(2/2) processed 360000 entries\n",
      "(2/2) processed 370000 entries\n",
      "(2/2) processed 380000 entries\n",
      "(2/2) processed 390000 entries\n",
      "(2/2) processed 400000 entries\n",
      "(2/2) processed 410000 entries\n",
      "(2/2) processed 420000 entries\n",
      "(2/2) processed 430000 entries\n",
      "(2/2) processed 440000 entries\n",
      "(2/2) processed 450000 entries\n",
      "(2/2) processed 460000 entries\n",
      "(2/2) processed 470000 entries\n",
      "(2/2) processed 480000 entries\n",
      "(2/2) processed 490000 entries\n",
      "(2/2) processed 500000 entries\n",
      "(2/2) processed 510000 entries\n",
      "(2/2) processed 520000 entries\n",
      "(2/2) processed 530000 entries\n",
      "(2/2) processed 540000 entries\n",
      "(2/2) processed 550000 entries\n",
      "(2/2) processed 560000 entries\n",
      "(2/2) processed 570000 entries\n",
      "(2/2) processed 580000 entries\n",
      "(2/2) processed 590000 entries\n",
      "(2/2) processed 600000 entries\n",
      "(2/2) processed 610000 entries\n",
      "(2/2) processed 620000 entries\n",
      "(2/2) processed 630000 entries\n",
      "(2/2) processed 640000 entries\n",
      "(2/2) processed 650000 entries\n",
      "(2/2) processed 660000 entries\n",
      "(2/2) processed 670000 entries\n",
      "(2/2) processed 680000 entries\n",
      "(2/2) processed 690000 entries\n",
      "(2/2) processed 700000 entries\n",
      "(2/2) processed 710000 entries\n",
      "(2/2) processed 720000 entries\n",
      "(2/2) processed 730000 entries\n",
      "(2/2) processed 740000 entries\n",
      "(2/2) processed 750000 entries\n",
      "(2/2) processed 760000 entries\n",
      "Include dump dumpGoogle.json ...\n",
      "Iterate over ../dumps/dumpGoogle.json ...\n",
      "(1/2)  processed 10000 entries\n",
      "(1/2)  processed 20000 entries\n",
      "(1/2)  processed 30000 entries\n",
      "(1/2)  processed 40000 entries\n",
      "(1/2)  processed 50000 entries\n",
      "(1/2)  processed 60000 entries\n",
      "(1/2)  processed 70000 entries\n",
      "(1/2)  processed 80000 entries\n",
      "(1/2)  processed 90000 entries\n",
      "(1/2)  processed 100000 entries\n",
      "(1/2)  processed 110000 entries\n",
      "(1/2)  processed 120000 entries\n",
      "(1/2)  processed 130000 entries\n",
      "(1/2)  processed 140000 entries\n",
      "(1/2)  processed 150000 entries\n",
      "(1/2)  processed 160000 entries\n",
      "(1/2)  processed 170000 entries\n",
      "(1/2)  processed 180000 entries\n",
      "(1/2)  processed 190000 entries\n",
      "(1/2)  processed 200000 entries\n",
      "(1/2)  processed 210000 entries\n",
      "(1/2)  processed 220000 entries\n",
      "(1/2)  processed 230000 entries\n",
      "(1/2)  processed 240000 entries\n",
      "(1/2)  processed 250000 entries\n",
      "(1/2)  processed 260000 entries\n",
      "(1/2)  processed 270000 entries\n",
      "(1/2)  processed 280000 entries\n",
      "(1/2)  processed 290000 entries\n",
      "(1/2)  processed 300000 entries\n",
      "(1/2)  processed 310000 entries\n",
      "(1/2)  processed 320000 entries\n",
      "(1/2)  processed 330000 entries\n",
      "(1/2)  processed 340000 entries\n",
      "(1/2)  processed 350000 entries\n",
      "(1/2)  processed 360000 entries\n",
      "(1/2)  processed 370000 entries\n",
      "(1/2)  processed 380000 entries\n",
      "(1/2)  processed 390000 entries\n",
      "(1/2)  processed 400000 entries\n",
      "(1/2)  processed 410000 entries\n",
      "(1/2)  processed 420000 entries\n",
      "(1/2)  processed 430000 entries\n",
      "(1/2)  processed 440000 entries\n",
      "(1/2)  processed 450000 entries\n",
      "(1/2)  processed 460000 entries\n",
      "(1/2)  processed 470000 entries\n",
      "(1/2)  processed 480000 entries\n",
      "(1/2)  processed 490000 entries\n",
      "(1/2)  processed 500000 entries\n",
      "(1/2)  processed 510000 entries\n",
      "(1/2)  processed 520000 entries\n",
      "(1/2)  processed 530000 entries\n",
      "(1/2)  processed 540000 entries\n",
      "(1/2)  processed 550000 entries\n",
      "(1/2)  processed 560000 entries\n",
      "(1/2)  processed 570000 entries\n",
      "(1/2)  processed 580000 entries\n",
      "(1/2)  processed 590000 entries\n",
      "(1/2)  processed 600000 entries\n",
      "(1/2)  processed 610000 entries\n",
      "(1/2)  processed 620000 entries\n",
      "(1/2)  processed 630000 entries\n",
      "(1/2)  processed 640000 entries\n",
      "Iterate over ../dumps/dumpGoogle.json ...\n",
      "(2/2) processed 10000 entries\n",
      "(2/2) processed 20000 entries\n",
      "(2/2) processed 30000 entries\n",
      "(2/2) processed 40000 entries\n",
      "(2/2) processed 50000 entries\n",
      "(2/2) processed 60000 entries\n",
      "(2/2) processed 70000 entries\n",
      "(2/2) processed 80000 entries\n",
      "(2/2) processed 90000 entries\n",
      "(2/2) processed 100000 entries\n",
      "(2/2) processed 110000 entries\n",
      "(2/2) processed 120000 entries\n",
      "(2/2) processed 130000 entries\n",
      "(2/2) processed 140000 entries\n",
      "(2/2) processed 150000 entries\n",
      "(2/2) processed 160000 entries\n",
      "(2/2) processed 170000 entries\n",
      "(2/2) processed 180000 entries\n",
      "(2/2) processed 190000 entries\n",
      "(2/2) processed 200000 entries\n",
      "(2/2) processed 210000 entries\n",
      "(2/2) processed 220000 entries\n",
      "(2/2) processed 230000 entries\n",
      "(2/2) processed 240000 entries\n",
      "(2/2) processed 250000 entries\n",
      "(2/2) processed 260000 entries\n",
      "(2/2) processed 270000 entries\n",
      "(2/2) processed 280000 entries\n",
      "(2/2) processed 290000 entries\n",
      "(2/2) processed 300000 entries\n",
      "(2/2) processed 310000 entries\n",
      "(2/2) processed 320000 entries\n",
      "(2/2) processed 330000 entries\n",
      "(2/2) processed 340000 entries\n",
      "(2/2) processed 350000 entries\n",
      "(2/2) processed 360000 entries\n",
      "(2/2) processed 370000 entries\n",
      "(2/2) processed 380000 entries\n",
      "(2/2) processed 390000 entries\n",
      "(2/2) processed 400000 entries\n",
      "(2/2) processed 410000 entries\n",
      "(2/2) processed 420000 entries\n",
      "(2/2) processed 430000 entries\n",
      "(2/2) processed 440000 entries\n",
      "(2/2) processed 450000 entries\n",
      "(2/2) processed 460000 entries\n",
      "(2/2) processed 470000 entries\n",
      "(2/2) processed 480000 entries\n",
      "(2/2) processed 490000 entries\n",
      "(2/2) processed 500000 entries\n",
      "(2/2) processed 510000 entries\n",
      "(2/2) processed 520000 entries\n",
      "(2/2) processed 530000 entries\n",
      "(2/2) processed 540000 entries\n",
      "(2/2) processed 550000 entries\n",
      "(2/2) processed 560000 entries\n",
      "(2/2) processed 570000 entries\n",
      "(2/2) processed 580000 entries\n",
      "(2/2) processed 590000 entries\n",
      "(2/2) processed 600000 entries\n",
      "(2/2) processed 610000 entries\n",
      "(2/2) processed 620000 entries\n",
      "(2/2) processed 630000 entries\n",
      "(2/2) processed 640000 entries\n",
      "Include dump dumpAzure.json ...\n",
      "Iterate over ../dumps/dumpAzure.json ...\n",
      "(1/2)  processed 10000 entries\n",
      "(1/2)  processed 20000 entries\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "(1/2)  processed 30000 entries\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "Other user agent, will filter: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0\n",
      "(1/2)  processed 40000 entries\n",
      "(1/2)  processed 50000 entries\n",
      "(1/2)  processed 60000 entries\n",
      "(1/2)  processed 70000 entries\n",
      "(1/2)  processed 80000 entries\n",
      "(1/2)  processed 90000 entries\n",
      "(1/2)  processed 100000 entries\n",
      "(1/2)  processed 110000 entries\n",
      "(1/2)  processed 120000 entries\n",
      "(1/2)  processed 130000 entries\n",
      "(1/2)  processed 140000 entries\n",
      "(1/2)  processed 150000 entries\n",
      "(1/2)  processed 160000 entries\n",
      "(1/2)  processed 170000 entries\n",
      "(1/2)  processed 180000 entries\n",
      "(1/2)  processed 190000 entries\n",
      "(1/2)  processed 200000 entries\n",
      "(1/2)  processed 210000 entries\n",
      "(1/2)  processed 220000 entries\n",
      "(1/2)  processed 230000 entries\n",
      "(1/2)  processed 240000 entries\n",
      "(1/2)  processed 250000 entries\n",
      "(1/2)  processed 260000 entries\n",
      "(1/2)  processed 270000 entries\n",
      "(1/2)  processed 280000 entries\n",
      "(1/2)  processed 290000 entries\n",
      "(1/2)  processed 300000 entries\n",
      "(1/2)  processed 310000 entries\n",
      "(1/2)  processed 320000 entries\n",
      "(1/2)  processed 330000 entries\n",
      "(1/2)  processed 340000 entries\n",
      "(1/2)  processed 350000 entries\n",
      "(1/2)  processed 360000 entries\n",
      "(1/2)  processed 370000 entries\n",
      "(1/2)  processed 380000 entries\n",
      "(1/2)  processed 390000 entries\n",
      "(1/2)  processed 400000 entries\n",
      "(1/2)  processed 410000 entries\n",
      "(1/2)  processed 420000 entries\n",
      "(1/2)  processed 430000 entries\n",
      "(1/2)  processed 440000 entries\n",
      "(1/2)  processed 450000 entries\n",
      "(1/2)  processed 460000 entries\n",
      "(1/2)  processed 470000 entries\n",
      "(1/2)  processed 480000 entries\n",
      "(1/2)  processed 490000 entries\n",
      "(1/2)  processed 500000 entries\n",
      "(1/2)  processed 510000 entries\n",
      "(1/2)  processed 520000 entries\n",
      "Iterate over ../dumps/dumpAzure.json ...\n",
      "(2/2) processed 10000 entries\n",
      "(2/2) processed 20000 entries\n",
      "context filter applied to context 1iypxp3t\n",
      "context filter applied to context 5phlicur\n",
      "(2/2) processed 30000 entries\n",
      "context filter applied to context 2nxjmsa0\n",
      "context filter applied to context 7vdy0y5s\n",
      "context filter applied to context bote7j8q\n",
      "context filter applied to context fm73iu8s\n",
      "context filter applied to context l0ibgdeb\n",
      "context filter applied to context rlv04nib\n",
      "context filter applied to context fbm76760\n",
      "context filter applied to context osh1al03\n",
      "context filter applied to context ybofmcq0\n",
      "context filter applied to context a9kr46a2\n",
      "context filter applied to context 84zb2os8\n",
      "context filter applied to context 0qo0gypk\n",
      "context filter applied to context 7r68dqne\n",
      "context filter applied to context sghdw5f1\n",
      "context filter applied to context b9wkerb7\n",
      "context filter applied to context 0eaqpndx\n",
      "context filter applied to context r4qqpxs3\n",
      "context filter applied to context d2t0pldx\n",
      "(2/2) processed 40000 entries\n",
      "(2/2) processed 50000 entries\n",
      "(2/2) processed 60000 entries\n",
      "(2/2) processed 70000 entries\n",
      "(2/2) processed 80000 entries\n",
      "(2/2) processed 90000 entries\n",
      "(2/2) processed 100000 entries\n",
      "(2/2) processed 110000 entries\n",
      "(2/2) processed 120000 entries\n",
      "(2/2) processed 130000 entries\n",
      "(2/2) processed 140000 entries\n",
      "(2/2) processed 150000 entries\n",
      "(2/2) processed 160000 entries\n",
      "(2/2) processed 170000 entries\n",
      "(2/2) processed 180000 entries\n",
      "(2/2) processed 190000 entries\n",
      "(2/2) processed 200000 entries\n",
      "(2/2) processed 210000 entries\n",
      "(2/2) processed 220000 entries\n",
      "(2/2) processed 230000 entries\n",
      "(2/2) processed 240000 entries\n",
      "(2/2) processed 250000 entries\n",
      "(2/2) processed 260000 entries\n",
      "(2/2) processed 270000 entries\n",
      "(2/2) processed 280000 entries\n",
      "(2/2) processed 290000 entries\n",
      "(2/2) processed 300000 entries\n",
      "(2/2) processed 310000 entries\n",
      "(2/2) processed 320000 entries\n",
      "(2/2) processed 330000 entries\n",
      "(2/2) processed 340000 entries\n",
      "(2/2) processed 350000 entries\n",
      "(2/2) processed 360000 entries\n",
      "(2/2) processed 370000 entries\n",
      "(2/2) processed 380000 entries\n",
      "(2/2) processed 390000 entries\n",
      "(2/2) processed 400000 entries\n",
      "(2/2) processed 410000 entries\n",
      "(2/2) processed 420000 entries\n",
      "(2/2) processed 430000 entries\n",
      "(2/2) processed 440000 entries\n",
      "(2/2) processed 450000 entries\n",
      "(2/2) processed 460000 entries\n",
      "(2/2) processed 470000 entries\n",
      "(2/2) processed 480000 entries\n",
      "(2/2) processed 490000 entries\n",
      "(2/2) processed 500000 entries\n",
      "(2/2) processed 510000 entries\n",
      "(2/2) processed 520000 entries\n"
     ]
    }
   ],
   "source": [
    "plotdata = []\n",
    "\n",
    "for dump in logdumps:\n",
    "    print(f\"Include dump {dump} ...\")\n",
    "    # Count entries to get some progress feedback\n",
    "    entries = 0\n",
    "    contexts = {}\n",
    "    otherUserAgentContextList = []\n",
    "\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(1/2)  processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        if isinstance(logentry, le.RequestLog):\n",
    "            userAgent = logentry.event['request']['headers']['user-agent']\n",
    "            if not (str(userAgent).startswith(\"node-fetch\") or str(userAgent).startswith(\"Artillery\")):\n",
    "                print(f\"Other user agent, will filter: {userAgent}\")\n",
    "                otherUserAgentContextList.append(logentry.context_id)\n",
    "\n",
    "    entries = 0\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(2/2) processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        if isinstance(logentry, le.PerfLog):\n",
    "            if logentry.type == \"measure\":\n",
    "                if logentry.function == \"frontend\":\n",
    "                    if not logentry.perf_type[1] == \"rpcOut\":\n",
    "\n",
    "                        id = logentry.context_id\n",
    "\n",
    "                        # Double-Check Context\n",
    "                        context_ok = True\n",
    "\n",
    "                        if id in otherUserAgentContextList:\n",
    "                            context_ok = False\n",
    "                            print(f\"context filter applied to context {id}\")\n",
    "\n",
    "                        if context_ok:\n",
    "                            # Create context if there isn't one\n",
    "                            if not (id in contexts):\n",
    "                                contexts[id] = []\n",
    "\n",
    "                            # Check if there is already an entry for this context\n",
    "                            if len(contexts[id]) > 0 :\n",
    "                                context_ok = False\n",
    "                                for checkEntry in contexts[id]:\n",
    "                                    if str(checkEntry) != str(entry):\n",
    "                                        # No duplicate -> problem\n",
    "                                        print(f\"ERROR: {id}: {len(contexts[id])}\")\n",
    "                                        tmp = le.cast_log_type(checkEntry)\n",
    "                                        print(f\"entry: {tmp.perf_type}#{tmp.type}#{tmp.perf_type_data}#{tmp.function}\")\n",
    "                                        print(f\"{tmp}\")\n",
    "                                        print(f\"NEW entry:\")\n",
    "                                        print(f\"entry: {logentry.perf_type}#{logentry.type}#{logentry.perf_type_data}#{logentry.function}\")\n",
    "                                        print(f\"{logentry}\")\n",
    "\n",
    "                            #Parse and add data entry if context check succeeded\n",
    "                            if context_ok :\n",
    "                                contexts[id].append(entry)\n",
    "\n",
    "                                function = logentry.perf_type_data\n",
    "                                duration = logentry.perf[\"duration\"]\n",
    "                                plattform = logentry.platform\n",
    "                                #print(f\"{id}#{function}#{duration}#{plattform}\")\n",
    "                                row = {}\n",
    "                                row[\"id\"] = id\n",
    "                                row[\"function\"] = function\n",
    "                                row[\"duration\"] = duration\n",
    "                                row[\"plattform\"] = plattform\n",
    "                                plotdata.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                     function     duration plattform\nid                                                  \n50eiztzf             /setUser     2.861503       aws\n87adsaks                    /   408.160138       aws\n7q2pl43z             /setUser     0.342887       aws\nauc39v1z  /product/:productId  1159.067847       aws\nukuuryrg  /product/:productId   233.554525       aws",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>function</th>\n      <th>duration</th>\n      <th>plattform</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>50eiztzf</th>\n      <td>/setUser</td>\n      <td>2.861503</td>\n      <td>aws</td>\n    </tr>\n    <tr>\n      <th>87adsaks</th>\n      <td>/</td>\n      <td>408.160138</td>\n      <td>aws</td>\n    </tr>\n    <tr>\n      <th>7q2pl43z</th>\n      <td>/setUser</td>\n      <td>0.342887</td>\n      <td>aws</td>\n    </tr>\n    <tr>\n      <th>auc39v1z</th>\n      <td>/product/:productId</td>\n      <td>1159.067847</td>\n      <td>aws</td>\n    </tr>\n    <tr>\n      <th>ukuuryrg</th>\n      <td>/product/:productId</td>\n      <td>233.554525</td>\n      <td>aws</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.DataFrame(plotdata)\n",
    "df_calls.set_index(\"id\", drop=True, inplace=True)\n",
    "\n",
    "df_calls.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_calls.to_pickle(oufile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}