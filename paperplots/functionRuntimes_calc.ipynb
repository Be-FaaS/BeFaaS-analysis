{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import befaas.logentry as le\n",
    "from befaas.fileutil import log_entry_iterator\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "logdumps = [\"dump_webservice_google.json\",\"dump_webservice_aws.json\",\"dump_webservice_azure.json\"]\n",
    "#logdumps = [\"dump_webservice_azure.json\"]\n",
    "oufile = \"../img/functionRuntimesEcomm.pkl\"\n",
    "print(\"Everything is set up.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump dump_webservice_google.json ...\n",
      "Iterate over ../dumps/dump_webservice_google.json ...\n",
      "(1/2)  processed 10000 entries\n",
      "(1/2)  processed 20000 entries\n",
      "(1/2)  processed 30000 entries\n",
      "(1/2)  processed 40000 entries\n",
      "(1/2)  processed 50000 entries\n",
      "(1/2)  processed 60000 entries\n",
      "(1/2)  processed 70000 entries\n",
      "(1/2)  processed 80000 entries\n",
      "(1/2)  processed 90000 entries\n",
      "(1/2)  processed 100000 entries\n",
      "(1/2)  processed 110000 entries\n",
      "(1/2)  processed 120000 entries\n",
      "(1/2)  processed 130000 entries\n",
      "(1/2)  processed 140000 entries\n",
      "(1/2)  processed 150000 entries\n",
      "(1/2)  processed 160000 entries\n",
      "(1/2)  processed 170000 entries\n",
      "(1/2)  processed 180000 entries\n",
      "(1/2)  processed 190000 entries\n",
      "(1/2)  processed 200000 entries\n",
      "(1/2)  processed 210000 entries\n",
      "(1/2)  processed 220000 entries\n",
      "(1/2)  processed 230000 entries\n",
      "(1/2)  processed 240000 entries\n",
      "(1/2)  processed 250000 entries\n",
      "(1/2)  processed 260000 entries\n",
      "(1/2)  processed 270000 entries\n",
      "(1/2)  processed 280000 entries\n",
      "(1/2)  processed 290000 entries\n",
      "(1/2)  processed 300000 entries\n",
      "(1/2)  processed 310000 entries\n",
      "(1/2)  processed 320000 entries\n",
      "(1/2)  processed 330000 entries\n",
      "(1/2)  processed 340000 entries\n",
      "(1/2)  processed 350000 entries\n",
      "(1/2)  processed 360000 entries\n",
      "(1/2)  processed 370000 entries\n",
      "(1/2)  processed 380000 entries\n",
      "(1/2)  processed 390000 entries\n",
      "(1/2)  processed 400000 entries\n",
      "(1/2)  processed 410000 entries\n",
      "(1/2)  processed 420000 entries\n",
      "(1/2)  processed 430000 entries\n",
      "(1/2)  processed 440000 entries\n",
      "(1/2)  processed 450000 entries\n",
      "(1/2)  processed 460000 entries\n",
      "(1/2)  processed 470000 entries\n",
      "(1/2)  processed 480000 entries\n",
      "(1/2)  processed 490000 entries\n",
      "(1/2)  processed 500000 entries\n",
      "(1/2)  processed 510000 entries\n",
      "(1/2)  processed 520000 entries\n",
      "(1/2)  processed 530000 entries\n",
      "(1/2)  processed 540000 entries\n",
      "(1/2)  processed 550000 entries\n",
      "Iterate over ../dumps/dump_webservice_google.json ...\n",
      "(2/2) processed 10000 entries\n",
      "(2/2) processed 20000 entries\n",
      "(2/2) processed 30000 entries\n",
      "(2/2) processed 40000 entries\n",
      "(2/2) processed 50000 entries\n",
      "(2/2) processed 60000 entries\n",
      "(2/2) processed 70000 entries\n",
      "(2/2) processed 80000 entries\n",
      "(2/2) processed 90000 entries\n",
      "(2/2) processed 100000 entries\n",
      "(2/2) processed 110000 entries\n",
      "(2/2) processed 120000 entries\n",
      "(2/2) processed 130000 entries\n",
      "(2/2) processed 140000 entries\n",
      "(2/2) processed 150000 entries\n",
      "(2/2) processed 160000 entries\n",
      "(2/2) processed 170000 entries\n",
      "(2/2) processed 180000 entries\n",
      "(2/2) processed 190000 entries\n",
      "(2/2) processed 200000 entries\n",
      "(2/2) processed 210000 entries\n",
      "(2/2) processed 220000 entries\n",
      "(2/2) processed 230000 entries\n",
      "(2/2) processed 240000 entries\n",
      "(2/2) processed 250000 entries\n",
      "(2/2) processed 260000 entries\n",
      "(2/2) processed 270000 entries\n",
      "(2/2) processed 280000 entries\n",
      "(2/2) processed 290000 entries\n",
      "(2/2) processed 300000 entries\n",
      "(2/2) processed 310000 entries\n",
      "(2/2) processed 320000 entries\n",
      "(2/2) processed 330000 entries\n",
      "(2/2) processed 340000 entries\n",
      "(2/2) processed 350000 entries\n",
      "(2/2) processed 360000 entries\n",
      "(2/2) processed 370000 entries\n",
      "(2/2) processed 380000 entries\n",
      "(2/2) processed 390000 entries\n",
      "(2/2) processed 400000 entries\n",
      "(2/2) processed 410000 entries\n",
      "(2/2) processed 420000 entries\n",
      "(2/2) processed 430000 entries\n",
      "(2/2) processed 440000 entries\n",
      "(2/2) processed 450000 entries\n",
      "(2/2) processed 460000 entries\n",
      "(2/2) processed 470000 entries\n",
      "(2/2) processed 480000 entries\n",
      "(2/2) processed 490000 entries\n",
      "(2/2) processed 500000 entries\n",
      "(2/2) processed 510000 entries\n",
      "(2/2) processed 520000 entries\n",
      "(2/2) processed 530000 entries\n",
      "(2/2) processed 540000 entries\n",
      "(2/2) processed 550000 entries\n",
      "Include dump dump_webservice_aws.json ...\n",
      "Iterate over ../dumps/dump_webservice_aws.json ...\n",
      "(1/2)  processed 10000 entries\n",
      "(1/2)  processed 20000 entries\n",
      "(1/2)  processed 30000 entries\n",
      "(1/2)  processed 40000 entries\n",
      "(1/2)  processed 50000 entries\n",
      "(1/2)  processed 60000 entries\n",
      "(1/2)  processed 70000 entries\n",
      "(1/2)  processed 80000 entries\n",
      "(1/2)  processed 90000 entries\n",
      "(1/2)  processed 100000 entries\n",
      "(1/2)  processed 110000 entries\n",
      "(1/2)  processed 120000 entries\n",
      "(1/2)  processed 130000 entries\n",
      "(1/2)  processed 140000 entries\n",
      "(1/2)  processed 150000 entries\n",
      "(1/2)  processed 160000 entries\n",
      "(1/2)  processed 170000 entries\n",
      "(1/2)  processed 180000 entries\n",
      "(1/2)  processed 190000 entries\n",
      "(1/2)  processed 200000 entries\n",
      "(1/2)  processed 210000 entries\n",
      "(1/2)  processed 220000 entries\n",
      "(1/2)  processed 230000 entries\n",
      "(1/2)  processed 240000 entries\n",
      "(1/2)  processed 250000 entries\n",
      "(1/2)  processed 260000 entries\n",
      "(1/2)  processed 270000 entries\n",
      "(1/2)  processed 280000 entries\n",
      "(1/2)  processed 290000 entries\n",
      "(1/2)  processed 300000 entries\n",
      "(1/2)  processed 310000 entries\n",
      "(1/2)  processed 320000 entries\n",
      "(1/2)  processed 330000 entries\n",
      "(1/2)  processed 340000 entries\n",
      "(1/2)  processed 350000 entries\n",
      "(1/2)  processed 360000 entries\n",
      "(1/2)  processed 370000 entries\n",
      "(1/2)  processed 380000 entries\n",
      "(1/2)  processed 390000 entries\n",
      "(1/2)  processed 400000 entries\n",
      "(1/2)  processed 410000 entries\n",
      "(1/2)  processed 420000 entries\n",
      "(1/2)  processed 430000 entries\n",
      "(1/2)  processed 440000 entries\n",
      "(1/2)  processed 450000 entries\n",
      "(1/2)  processed 460000 entries\n",
      "(1/2)  processed 470000 entries\n",
      "(1/2)  processed 480000 entries\n",
      "(1/2)  processed 490000 entries\n",
      "(1/2)  processed 500000 entries\n",
      "(1/2)  processed 510000 entries\n",
      "(1/2)  processed 520000 entries\n",
      "(1/2)  processed 530000 entries\n",
      "(1/2)  processed 540000 entries\n",
      "(1/2)  processed 550000 entries\n",
      "(1/2)  processed 560000 entries\n",
      "(1/2)  processed 570000 entries\n",
      "(1/2)  processed 580000 entries\n",
      "(1/2)  processed 590000 entries\n",
      "(1/2)  processed 600000 entries\n",
      "(1/2)  processed 610000 entries\n",
      "(1/2)  processed 620000 entries\n",
      "(1/2)  processed 630000 entries\n",
      "Iterate over ../dumps/dump_webservice_aws.json ...\n",
      "(2/2) processed 10000 entries\n",
      "(2/2) processed 20000 entries\n",
      "(2/2) processed 30000 entries\n",
      "(2/2) processed 40000 entries\n",
      "(2/2) processed 50000 entries\n",
      "(2/2) processed 60000 entries\n",
      "(2/2) processed 70000 entries\n",
      "(2/2) processed 80000 entries\n",
      "(2/2) processed 90000 entries\n",
      "(2/2) processed 100000 entries\n",
      "(2/2) processed 110000 entries\n",
      "(2/2) processed 120000 entries\n",
      "(2/2) processed 130000 entries\n",
      "(2/2) processed 140000 entries\n",
      "(2/2) processed 150000 entries\n",
      "(2/2) processed 160000 entries\n",
      "(2/2) processed 170000 entries\n",
      "(2/2) processed 180000 entries\n",
      "(2/2) processed 190000 entries\n",
      "(2/2) processed 200000 entries\n",
      "(2/2) processed 210000 entries\n",
      "(2/2) processed 220000 entries\n",
      "(2/2) processed 230000 entries\n",
      "(2/2) processed 240000 entries\n",
      "(2/2) processed 250000 entries\n",
      "(2/2) processed 260000 entries\n",
      "(2/2) processed 270000 entries\n",
      "(2/2) processed 280000 entries\n",
      "(2/2) processed 290000 entries\n",
      "(2/2) processed 300000 entries\n",
      "(2/2) processed 310000 entries\n",
      "(2/2) processed 320000 entries\n",
      "(2/2) processed 330000 entries\n",
      "(2/2) processed 340000 entries\n",
      "(2/2) processed 350000 entries\n",
      "(2/2) processed 360000 entries\n",
      "(2/2) processed 370000 entries\n",
      "(2/2) processed 380000 entries\n",
      "(2/2) processed 390000 entries\n",
      "(2/2) processed 400000 entries\n",
      "(2/2) processed 410000 entries\n",
      "(2/2) processed 420000 entries\n",
      "(2/2) processed 430000 entries\n",
      "(2/2) processed 440000 entries\n",
      "(2/2) processed 450000 entries\n",
      "(2/2) processed 460000 entries\n",
      "(2/2) processed 470000 entries\n",
      "(2/2) processed 480000 entries\n",
      "(2/2) processed 490000 entries\n",
      "(2/2) processed 500000 entries\n",
      "(2/2) processed 510000 entries\n",
      "(2/2) processed 520000 entries\n",
      "(2/2) processed 530000 entries\n",
      "(2/2) processed 540000 entries\n",
      "(2/2) processed 550000 entries\n",
      "(2/2) processed 560000 entries\n",
      "(2/2) processed 570000 entries\n",
      "(2/2) processed 580000 entries\n",
      "(2/2) processed 590000 entries\n",
      "(2/2) processed 600000 entries\n",
      "(2/2) processed 610000 entries\n",
      "(2/2) processed 620000 entries\n",
      "(2/2) processed 630000 entries\n",
      "Include dump dump_webservice_azure.json ...\n",
      "Iterate over ../dumps/dump_webservice_azure.json ...\n",
      "(1/2)  processed 10000 entries\n",
      "(1/2)  processed 20000 entries\n",
      "(1/2)  processed 30000 entries\n",
      "(1/2)  processed 40000 entries\n",
      "(1/2)  processed 50000 entries\n",
      "(1/2)  processed 60000 entries\n",
      "(1/2)  processed 70000 entries\n",
      "(1/2)  processed 80000 entries\n",
      "(1/2)  processed 90000 entries\n",
      "(1/2)  processed 100000 entries\n",
      "(1/2)  processed 110000 entries\n",
      "(1/2)  processed 120000 entries\n",
      "(1/2)  processed 130000 entries\n",
      "(1/2)  processed 140000 entries\n",
      "(1/2)  processed 150000 entries\n",
      "(1/2)  processed 160000 entries\n",
      "(1/2)  processed 170000 entries\n",
      "(1/2)  processed 180000 entries\n",
      "(1/2)  processed 190000 entries\n",
      "(1/2)  processed 200000 entries\n",
      "(1/2)  processed 210000 entries\n",
      "(1/2)  processed 220000 entries\n",
      "(1/2)  processed 230000 entries\n",
      "(1/2)  processed 240000 entries\n",
      "(1/2)  processed 250000 entries\n",
      "(1/2)  processed 260000 entries\n",
      "(1/2)  processed 270000 entries\n",
      "(1/2)  processed 280000 entries\n",
      "(1/2)  processed 290000 entries\n",
      "(1/2)  processed 300000 entries\n",
      "(1/2)  processed 310000 entries\n",
      "(1/2)  processed 320000 entries\n",
      "(1/2)  processed 330000 entries\n",
      "(1/2)  processed 340000 entries\n",
      "(1/2)  processed 350000 entries\n",
      "(1/2)  processed 360000 entries\n",
      "(1/2)  processed 370000 entries\n",
      "(1/2)  processed 380000 entries\n",
      "(1/2)  processed 390000 entries\n",
      "(1/2)  processed 400000 entries\n",
      "(1/2)  processed 410000 entries\n",
      "(1/2)  processed 420000 entries\n",
      "(1/2)  processed 430000 entries\n",
      "(1/2)  processed 440000 entries\n",
      "(1/2)  processed 450000 entries\n",
      "(1/2)  processed 460000 entries\n",
      "(1/2)  processed 470000 entries\n",
      "(1/2)  processed 480000 entries\n",
      "(1/2)  processed 490000 entries\n",
      "(1/2)  processed 500000 entries\n",
      "(1/2)  processed 510000 entries\n",
      "(1/2)  processed 520000 entries\n",
      "(1/2)  processed 530000 entries\n",
      "Iterate over ../dumps/dump_webservice_azure.json ...\n",
      "(2/2) processed 10000 entries\n",
      "(2/2) processed 20000 entries\n",
      "(2/2) processed 30000 entries\n",
      "(2/2) processed 40000 entries\n",
      "(2/2) processed 50000 entries\n",
      "(2/2) processed 60000 entries\n",
      "(2/2) processed 70000 entries\n",
      "(2/2) processed 80000 entries\n",
      "(2/2) processed 90000 entries\n",
      "(2/2) processed 100000 entries\n",
      "(2/2) processed 110000 entries\n",
      "(2/2) processed 120000 entries\n",
      "(2/2) processed 130000 entries\n",
      "(2/2) processed 140000 entries\n",
      "(2/2) processed 150000 entries\n",
      "(2/2) processed 160000 entries\n",
      "(2/2) processed 170000 entries\n",
      "(2/2) processed 180000 entries\n",
      "(2/2) processed 190000 entries\n",
      "(2/2) processed 200000 entries\n",
      "(2/2) processed 210000 entries\n",
      "(2/2) processed 220000 entries\n",
      "(2/2) processed 230000 entries\n",
      "(2/2) processed 240000 entries\n",
      "(2/2) processed 250000 entries\n",
      "(2/2) processed 260000 entries\n",
      "(2/2) processed 270000 entries\n",
      "(2/2) processed 280000 entries\n",
      "(2/2) processed 290000 entries\n",
      "(2/2) processed 300000 entries\n",
      "(2/2) processed 310000 entries\n",
      "(2/2) processed 320000 entries\n",
      "(2/2) processed 330000 entries\n",
      "(2/2) processed 340000 entries\n",
      "(2/2) processed 350000 entries\n",
      "(2/2) processed 360000 entries\n",
      "(2/2) processed 370000 entries\n",
      "(2/2) processed 380000 entries\n",
      "(2/2) processed 390000 entries\n",
      "(2/2) processed 400000 entries\n",
      "(2/2) processed 410000 entries\n",
      "(2/2) processed 420000 entries\n",
      "(2/2) processed 430000 entries\n",
      "(2/2) processed 440000 entries\n",
      "(2/2) processed 450000 entries\n",
      "(2/2) processed 460000 entries\n",
      "(2/2) processed 470000 entries\n",
      "(2/2) processed 480000 entries\n",
      "(2/2) processed 490000 entries\n",
      "(2/2) processed 500000 entries\n",
      "(2/2) processed 510000 entries\n",
      "(2/2) processed 520000 entries\n",
      "(2/2) processed 530000 entries\n"
     ]
    }
   ],
   "source": [
    "plotdata = []\n",
    "\n",
    "for dump in logdumps:\n",
    "    print(f\"Include dump {dump} ...\")\n",
    "    # Count entries to get some progress feedback\n",
    "    entries = 0\n",
    "    contexts = {}\n",
    "    otherUserAgentContextList = []\n",
    "\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(1/2)  processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        if isinstance(logentry, le.RequestLog):\n",
    "            userAgent = logentry.event['request']['headers']['user-agent']\n",
    "            if not (str(userAgent).startswith(\"node-fetch\") or str(userAgent).startswith(\"Artillery\")):\n",
    "                print(f\"Other user agent, will filter: {userAgent}\")\n",
    "                otherUserAgentContextList.append(logentry.context_id)\n",
    "\n",
    "    entries = 0\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(2/2) processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        if isinstance(logentry, le.PerfLog):\n",
    "            if logentry.type == \"measure\":\n",
    "                if logentry.function == \"frontend\":\n",
    "                    if not logentry.perf_type[1] == \"rpcOut\":\n",
    "\n",
    "                        id = logentry.context_id\n",
    "\n",
    "                        # Double-Check Context\n",
    "                        context_ok = True\n",
    "\n",
    "                        if id in otherUserAgentContextList:\n",
    "                            context_ok = False\n",
    "                            print(f\"context filter applied to context {id}\")\n",
    "\n",
    "                        if context_ok:\n",
    "                            # Create context if there isn't one\n",
    "                            if not (id in contexts):\n",
    "                                contexts[id] = []\n",
    "\n",
    "                            # Check if there is already an entry for this context\n",
    "                            if len(contexts[id]) > 0 :\n",
    "                                context_ok = False\n",
    "                                for checkEntry in contexts[id]:\n",
    "                                    if str(checkEntry) != str(entry):\n",
    "                                        # No duplicate -> problem\n",
    "                                        print(f\"ERROR: {id}: {len(contexts[id])}\")\n",
    "                                        tmp = le.cast_log_type(checkEntry)\n",
    "                                        print(f\"entry: {tmp.perf_type}#{tmp.type}#{tmp.perf_type_data}#{tmp.function}\")\n",
    "                                        print(f\"{tmp}\")\n",
    "                                        print(f\"NEW entry:\")\n",
    "                                        print(f\"entry: {logentry.perf_type}#{logentry.type}#{logentry.perf_type_data}#{logentry.function}\")\n",
    "                                        print(f\"{logentry}\")\n",
    "\n",
    "                            #Parse and add data entry if context check succeeded\n",
    "                            if context_ok :\n",
    "                                contexts[id].append(entry)\n",
    "\n",
    "                                function = logentry.perf_type_data\n",
    "                                duration = logentry.perf[\"duration\"]\n",
    "                                plattform = logentry.platform\n",
    "                                #print(f\"{id}#{function}#{duration}#{plattform}\")\n",
    "                                if (duration > 0):\n",
    "                                    row = {}\n",
    "                                    row[\"id\"] = id\n",
    "                                    row[\"function\"] = function\n",
    "                                    row[\"duration\"] = duration\n",
    "                                    row[\"plattform\"] = plattform\n",
    "                                    plotdata.append(row)\n",
    "                                else:\n",
    "                                    print(f\"Error: {id}#{function}#{duration}#{plattform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                     function    duration plattform\nid                                                 \nalat1zgg            /checkout  430.411724    google\nb6thrhrv                /cart  162.080742    google\n05zs9a2w  /product/:productId   78.121755    google\n96avaqpj  /product/:productId  112.281232    google\n8fcwchf4         /addCartItem   69.495420    google",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>function</th>\n      <th>duration</th>\n      <th>plattform</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alat1zgg</th>\n      <td>/checkout</td>\n      <td>430.411724</td>\n      <td>google</td>\n    </tr>\n    <tr>\n      <th>b6thrhrv</th>\n      <td>/cart</td>\n      <td>162.080742</td>\n      <td>google</td>\n    </tr>\n    <tr>\n      <th>05zs9a2w</th>\n      <td>/product/:productId</td>\n      <td>78.121755</td>\n      <td>google</td>\n    </tr>\n    <tr>\n      <th>96avaqpj</th>\n      <td>/product/:productId</td>\n      <td>112.281232</td>\n      <td>google</td>\n    </tr>\n    <tr>\n      <th>8fcwchf4</th>\n      <td>/addCartItem</td>\n      <td>69.495420</td>\n      <td>google</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.DataFrame(plotdata)\n",
    "df_calls.set_index(\"id\", drop=True, inplace=True)\n",
    "\n",
    "df_calls.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_calls.to_pickle(oufile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}