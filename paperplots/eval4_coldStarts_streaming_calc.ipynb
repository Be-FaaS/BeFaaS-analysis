{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json_coder\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import befaas as bf\n",
    "import befaas.logentry as le\n",
    "from befaas.graph import build_function_graph, add_default_metadata, conv_to_ms\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "logdumps = [\"dump_streaming_google.json\",\"dump_streaming_aws.json\",\"dump_streaming_azure.json\"]\n",
    "#logdumps = [\"dump_streaming_google.json\",\"dump_streaming_aws.json\"]\n",
    "#logdumps = [\"dump_streaming_aws.json\"]\n",
    "#logdumps = [\"dump_streaming_azure.json\"]\n",
    "outfile = \"../img/2023_streaming_coldStarts.pkl\"\n",
    "plotdata = []\n",
    "\n",
    "print(\"Everything is set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump dump_streaming_google.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts and find cold starts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Find experiment start...\n",
      "done.\n",
      "n=15257 measurements for google\n",
      "Analyze cold starts...\n",
      "Done.\n",
      "Include dump dump_streaming_aws.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts and find cold starts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Find experiment start...\n",
      "done.\n",
      "n=15454 measurements for aws\n",
      "Analyze cold starts...\n",
      "Error: {\"Provider\": \"aws\", \"function\": \"patchUserMeta\", \"kind\": \"coldstart\", \"start\": 2208, \"latency\": 0}\n",
      "Done.\n",
      "Include dump dump_streaming_azure.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts and find cold starts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Find experiment start...\n",
      "done.\n",
      "n=9143 measurements for \n",
      "Analyze cold starts...\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"addVideo\", \"kind\": \"coldstart\", \"start\": 6828, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"authDevice\", \"kind\": \"coldstart\", \"start\": 6829, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"getUserMeta\", \"kind\": \"coldstart\", \"start\": 6829, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"getVideos\", \"kind\": \"coldstart\", \"start\": 6829, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"patchUserMeta\", \"kind\": \"coldstart\", \"start\": 6829, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"registerDevice\", \"kind\": \"coldstart\", \"start\": 6829, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"registerUser\", \"kind\": \"coldstart\", \"start\": 6829, \"latency\": 0}\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debugpairs = []\n",
    "for dump in logdumps:\n",
    "    print(f\"Include dump {dump} ...\")\n",
    "    print(\"Load dump... (may take a while)\")\n",
    "    data = bf.load_logs(filepath + dump)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    print(\"Sort data to contexts and find cold starts...\")\n",
    "    contexts = {}\n",
    "    coldtsarts = []\n",
    "    experimentStart = None\n",
    "\n",
    "    for entry in data:\n",
    "        id = entry.context_id\n",
    "        if id == None:\n",
    "            if isinstance(entry, le.ColdstartLog):\n",
    "                coldtsarts.append(entry)\n",
    "            else:\n",
    "                print(\"Some other log entry type\")\n",
    "\n",
    "        if not id == None:\n",
    "            if not (id in contexts):\n",
    "                contexts[id] = []\n",
    "\n",
    "            contexts[id].append(entry)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    print(\"Find xpairs...\")\n",
    "    xpairs = {}\n",
    "\n",
    "    for ctx_id in contexts:\n",
    "        ctx = contexts[ctx_id]\n",
    "        for entry in ctx:\n",
    "            id = entry.event[\"xPair\"]\n",
    "            if not (id in xpairs):\n",
    "                xpairs[id] = []\n",
    "\n",
    "            specialPair = False\n",
    "            if isinstance(entry, le.PerfLog):\n",
    "                if not entry.perf_type_data == \"\":\n",
    "                    parts = entry.perf_type_data.split(\":\")\n",
    "                    if len(parts) > 1:\n",
    "                        id = parts[1]\n",
    "                        if not (id in xpairs):\n",
    "                            xpairs[id] = []\n",
    "                        xpairs[id].append(entry)\n",
    "                        specialPair = True\n",
    "\n",
    "            if not specialPair:\n",
    "                xpairs[id].append(entry)\n",
    "    print(\"done.\")\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    print(\"Find experiment start...\")\n",
    "    for xpairID in xpairs:\n",
    "        xpair = xpairs[xpairID]\n",
    "        for entry in xpair:\n",
    "            if not isinstance(entry, le.ArtilleryLog):\n",
    "                if experimentStart is None :\n",
    "                    experimentStart = entry.timestamp\n",
    "                if entry.timestamp < experimentStart:\n",
    "                    experimentStart = entry.timestamp\n",
    "    print(\"done.\")\n",
    "\n",
    "    n = 0\n",
    "    for xpairID in xpairs:\n",
    "        xpair = xpairs[xpairID]\n",
    "\n",
    "        requestStart = None\n",
    "        requestEnd = None\n",
    "        function = \"\"\n",
    "        platform = \"\"\n",
    "        latency = -10\n",
    "\n",
    "        if len(xpair) == 2:\n",
    "            if str(xpair[0].url).__contains__(\"azure\"):\n",
    "                continue\n",
    "                for entry in xpair:\n",
    "                    if isinstance(entry, le.ArtilleryLog):\n",
    "                        if entry.type == \"before\":\n",
    "                           requestStart = entry.timestamp\n",
    "                        if entry.type == \"after\":\n",
    "                           requestEnd = entry.timestamp\n",
    "                           function = str(entry.url).split(\"/\")[-1]\n",
    "                           platform = \"azure\"\n",
    "            else:\n",
    "                print(\"Error for \" + xpair[0].url)\n",
    "        else:\n",
    "            for entry in xpair:\n",
    "                if isinstance(entry, le.PerfLog):\n",
    "                    if str(entry.perf_type[0]) == \"start\" and not str(entry.perf_type[1]).__contains__(\"db\"):\n",
    "                        requestStart = entry.timestamp\n",
    "                    if str(entry.perf_type[0]) == \"measure\" and not str(entry.perf_type[1]).__contains__(\"db\"):\n",
    "                        latency = entry.perf[\"duration\"]\n",
    "                if isinstance(entry, le.RequestLog):\n",
    "                    function = entry.function\n",
    "                    platform = entry.platform\n",
    "                    if requestStart == None:\n",
    "                        requestStart = entry.timestamp\n",
    "                    else:\n",
    "                        if (entry.timestamp < requestStart):\n",
    "                            requestStart = entry.timestamp\n",
    "\n",
    "        #latency = (requestEnd - requestStart).microseconds / 1000\n",
    "\n",
    "        if not platform == \"\" and latency > 0 and requestStart is not None :\n",
    "            row = {}\n",
    "            row[\"Provider\"] = platform\n",
    "            row[\"function\"] = function\n",
    "            row[\"kind\"] = \"request\"\n",
    "            row[\"start\"] = (requestStart - experimentStart).seconds\n",
    "            row[\"latency\"] = latency\n",
    "\n",
    "            if row[\"start\"] < 4000:\n",
    "                plotdata.append(row)\n",
    "                n = n+1\n",
    "            else:\n",
    "                print(\"Error: \" + json.dumps(row))\n",
    "        else:\n",
    "            debugpairs.append(xpair)\n",
    "\n",
    "    print(\"n=\" + str(n) + \" measurements for \" + platform)\n",
    "\n",
    "    print(\"Analyze cold starts...\")\n",
    "\n",
    "    for cold in coldtsarts:\n",
    "        if not cold.platform == \"artillery\":\n",
    "            row = {}\n",
    "            row[\"Provider\"] = cold.platform\n",
    "            row[\"function\"] = cold.function\n",
    "            row[\"kind\"] = \"coldstart\"\n",
    "            start = (cold.timestamp - experimentStart).seconds\n",
    "            if start > 80000:\n",
    "                start = start - 86400\n",
    "            if start < 0:\n",
    "                start = 0\n",
    "            row[\"start\"] = start\n",
    "            row[\"latency\"] = 0\n",
    "\n",
    "            if row[\"start\"] < 2100:\n",
    "                plotdata.append(row)\n",
    "            else:\n",
    "                print(\"Error: \" + json.dumps(row))\n",
    "                debugpairs.append(cold)\n",
    "\n",
    "\n",
    "    print(\"Done.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Provider        function     kind  start    latency\n",
      "0   google    registerUser  request      0  14.187894\n",
      "1   google  registerDevice  request      0  87.973293\n",
      "2   google  registerDevice  request      0  17.420433\n",
      "3   google    registerUser  request      0  10.535028\n",
      "4   google  registerDevice  request      0  17.148184\n"
     ]
    },
    {
     "data": {
      "text/plain": "              start       latency\ncount  39960.000000  39960.000000\nmean    1245.856957     12.135366\nstd      762.566179     17.117890\nmin        0.000000      0.000000\n25%      211.000000      2.382563\n50%     1682.000000      4.702271\n75%     1794.000000     17.154608\nmax     2002.000000    327.226993",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>latency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>39960.000000</td>\n      <td>39960.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1245.856957</td>\n      <td>12.135366</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>762.566179</td>\n      <td>17.117890</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>211.000000</td>\n      <td>2.382563</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1682.000000</td>\n      <td>4.702271</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1794.000000</td>\n      <td>17.154608</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2002.000000</td>\n      <td>327.226993</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.DataFrame(plotdata)\n",
    "print(df_calls.head())\n",
    "df_calls.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_calls.to_pickle(outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}