{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import befaas.logentry as le\n",
    "from befaas.fileutil import log_entry_iterator\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "#logdumps = [\"dump_webservice_aws.json\"]\n",
    "logdumps = [\"dump_webservice_aws.json\",\"dump_webservice_google.json\",\"dump_webservice_azure.json\"]\n",
    "oufile = \"../img/computeNetworkDbEcomm.pkl\"\n",
    "\n",
    "print(\"Everything is set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump dump_webservice_aws.json ...\n",
      "Iterate over ../dumps/dump_webservice_aws.json ...\n",
      "(I)  processed 10000 entries\n",
      "(I)  processed 20000 entries\n",
      "(I)  processed 30000 entries\n",
      "(I)  processed 40000 entries\n",
      "(I)  processed 50000 entries\n",
      "(I)  processed 60000 entries\n",
      "(I)  processed 70000 entries\n",
      "(I)  processed 80000 entries\n",
      "(I)  processed 90000 entries\n",
      "(I)  processed 100000 entries\n",
      "(I)  processed 110000 entries\n",
      "(I)  processed 120000 entries\n",
      "(I)  processed 130000 entries\n",
      "(I)  processed 140000 entries\n",
      "(I)  processed 150000 entries\n",
      "(I)  processed 160000 entries\n",
      "(I)  processed 170000 entries\n",
      "(I)  processed 180000 entries\n",
      "(I)  processed 190000 entries\n",
      "(I)  processed 200000 entries\n",
      "(I)  processed 210000 entries\n",
      "(I)  processed 220000 entries\n",
      "(I)  processed 230000 entries\n",
      "(I)  processed 240000 entries\n",
      "(I)  processed 250000 entries\n",
      "(I)  processed 260000 entries\n",
      "(I)  processed 270000 entries\n",
      "(I)  processed 280000 entries\n",
      "(I)  processed 290000 entries\n",
      "(I)  processed 300000 entries\n",
      "(I)  processed 310000 entries\n",
      "(I)  processed 320000 entries\n",
      "(I)  processed 330000 entries\n",
      "(I)  processed 340000 entries\n",
      "(I)  processed 350000 entries\n",
      "(I)  processed 360000 entries\n",
      "(I)  processed 370000 entries\n",
      "(I)  processed 380000 entries\n",
      "(I)  processed 390000 entries\n",
      "(I)  processed 400000 entries\n",
      "(I)  processed 410000 entries\n",
      "(I)  processed 420000 entries\n",
      "(I)  processed 430000 entries\n",
      "(I)  processed 440000 entries\n",
      "(I)  processed 450000 entries\n",
      "(I)  processed 460000 entries\n",
      "(I)  processed 470000 entries\n",
      "(I)  processed 480000 entries\n",
      "(I)  processed 490000 entries\n",
      "(I)  processed 500000 entries\n",
      "(I)  processed 510000 entries\n",
      "(I)  processed 520000 entries\n",
      "(I)  processed 530000 entries\n",
      "(I)  processed 540000 entries\n",
      "(I)  processed 550000 entries\n",
      "(I)  processed 560000 entries\n",
      "(I)  processed 570000 entries\n",
      "(I)  processed 580000 entries\n",
      "(I)  processed 590000 entries\n",
      "(I)  processed 600000 entries\n",
      "(I)  processed 610000 entries\n",
      "(I)  processed 620000 entries\n",
      "(I)  processed 630000 entries\n",
      "Iterate over ../dumps/dump_webservice_aws.json ...\n",
      "(II) processed 10000 entries\n",
      "(II) processed 20000 entries\n",
      "(II) processed 30000 entries\n",
      "(II) processed 40000 entries\n",
      "(II) processed 50000 entries\n",
      "(II) processed 60000 entries\n",
      "(II) processed 70000 entries\n",
      "(II) processed 80000 entries\n",
      "(II) processed 90000 entries\n",
      "(II) processed 100000 entries\n",
      "(II) processed 110000 entries\n",
      "(II) processed 120000 entries\n",
      "(II) processed 130000 entries\n",
      "(II) processed 140000 entries\n",
      "(II) processed 150000 entries\n",
      "(II) processed 160000 entries\n",
      "(II) processed 170000 entries\n",
      "(II) processed 180000 entries\n",
      "(II) processed 190000 entries\n",
      "(II) processed 200000 entries\n",
      "(II) processed 210000 entries\n",
      "(II) processed 220000 entries\n",
      "(II) processed 230000 entries\n",
      "(II) processed 240000 entries\n",
      "(II) processed 250000 entries\n",
      "(II) processed 260000 entries\n",
      "(II) processed 270000 entries\n",
      "(II) processed 280000 entries\n",
      "(II) processed 290000 entries\n",
      "(II) processed 300000 entries\n",
      "(II) processed 310000 entries\n",
      "(II) processed 320000 entries\n",
      "(II) processed 330000 entries\n",
      "(II) processed 340000 entries\n",
      "(II) processed 350000 entries\n",
      "(II) processed 360000 entries\n",
      "(II) processed 370000 entries\n",
      "(II) processed 380000 entries\n",
      "(II) processed 390000 entries\n",
      "(II) processed 400000 entries\n",
      "(II) processed 410000 entries\n",
      "(II) processed 420000 entries\n",
      "(II) processed 430000 entries\n",
      "(II) processed 440000 entries\n",
      "(II) processed 450000 entries\n",
      "(II) processed 460000 entries\n",
      "(II) processed 470000 entries\n",
      "(II) processed 480000 entries\n",
      "(II) processed 490000 entries\n",
      "(II) processed 500000 entries\n",
      "(II) processed 510000 entries\n",
      "(II) processed 520000 entries\n",
      "(II) processed 530000 entries\n",
      "(II) processed 540000 entries\n",
      "(II) processed 550000 entries\n",
      "(II) processed 560000 entries\n",
      "(II) processed 570000 entries\n",
      "(II) processed 580000 entries\n",
      "(II) processed 590000 entries\n",
      "(II) processed 600000 entries\n",
      "(II) processed 610000 entries\n",
      "(II) processed 620000 entries\n",
      "(II) processed 630000 entries\n",
      "Include dump dump_webservice_google.json ...\n",
      "Iterate over ../dumps/dump_webservice_google.json ...\n",
      "(I)  processed 10000 entries\n",
      "(I)  processed 20000 entries\n",
      "(I)  processed 30000 entries\n",
      "(I)  processed 40000 entries\n",
      "(I)  processed 50000 entries\n",
      "(I)  processed 60000 entries\n",
      "(I)  processed 70000 entries\n",
      "(I)  processed 80000 entries\n",
      "(I)  processed 90000 entries\n",
      "(I)  processed 100000 entries\n",
      "(I)  processed 110000 entries\n",
      "(I)  processed 120000 entries\n",
      "(I)  processed 130000 entries\n",
      "(I)  processed 140000 entries\n",
      "(I)  processed 150000 entries\n",
      "(I)  processed 160000 entries\n",
      "(I)  processed 170000 entries\n",
      "(I)  processed 180000 entries\n",
      "(I)  processed 190000 entries\n",
      "(I)  processed 200000 entries\n",
      "(I)  processed 210000 entries\n",
      "(I)  processed 220000 entries\n",
      "(I)  processed 230000 entries\n",
      "(I)  processed 240000 entries\n",
      "(I)  processed 250000 entries\n",
      "(I)  processed 260000 entries\n",
      "(I)  processed 270000 entries\n",
      "(I)  processed 280000 entries\n",
      "(I)  processed 290000 entries\n",
      "(I)  processed 300000 entries\n",
      "(I)  processed 310000 entries\n",
      "(I)  processed 320000 entries\n",
      "(I)  processed 330000 entries\n",
      "(I)  processed 340000 entries\n",
      "(I)  processed 350000 entries\n",
      "(I)  processed 360000 entries\n",
      "(I)  processed 370000 entries\n",
      "(I)  processed 380000 entries\n",
      "(I)  processed 390000 entries\n",
      "(I)  processed 400000 entries\n",
      "(I)  processed 410000 entries\n",
      "(I)  processed 420000 entries\n",
      "(I)  processed 430000 entries\n",
      "(I)  processed 440000 entries\n",
      "(I)  processed 450000 entries\n",
      "(I)  processed 460000 entries\n",
      "(I)  processed 470000 entries\n",
      "(I)  processed 480000 entries\n",
      "(I)  processed 490000 entries\n",
      "(I)  processed 500000 entries\n",
      "(I)  processed 510000 entries\n",
      "(I)  processed 520000 entries\n",
      "(I)  processed 530000 entries\n",
      "(I)  processed 540000 entries\n",
      "(I)  processed 550000 entries\n",
      "Iterate over ../dumps/dump_webservice_google.json ...\n",
      "(II) processed 10000 entries\n",
      "(II) processed 20000 entries\n",
      "(II) processed 30000 entries\n",
      "(II) processed 40000 entries\n",
      "(II) processed 50000 entries\n",
      "(II) processed 60000 entries\n",
      "(II) processed 70000 entries\n",
      "(II) processed 80000 entries\n",
      "(II) processed 90000 entries\n",
      "(II) processed 100000 entries\n",
      "(II) processed 110000 entries\n",
      "(II) processed 120000 entries\n",
      "(II) processed 130000 entries\n",
      "(II) processed 140000 entries\n",
      "(II) processed 150000 entries\n",
      "(II) processed 160000 entries\n",
      "(II) processed 170000 entries\n",
      "(II) processed 180000 entries\n",
      "(II) processed 190000 entries\n",
      "(II) processed 200000 entries\n",
      "(II) processed 210000 entries\n",
      "(II) processed 220000 entries\n",
      "(II) processed 230000 entries\n",
      "(II) processed 240000 entries\n",
      "(II) processed 250000 entries\n",
      "(II) processed 260000 entries\n",
      "(II) processed 270000 entries\n",
      "(II) processed 280000 entries\n",
      "(II) processed 290000 entries\n",
      "(II) processed 300000 entries\n",
      "(II) processed 310000 entries\n",
      "(II) processed 320000 entries\n",
      "(II) processed 330000 entries\n",
      "(II) processed 340000 entries\n",
      "(II) processed 350000 entries\n",
      "(II) processed 360000 entries\n",
      "(II) processed 370000 entries\n",
      "(II) processed 380000 entries\n",
      "(II) processed 390000 entries\n",
      "(II) processed 400000 entries\n",
      "(II) processed 410000 entries\n",
      "(II) processed 420000 entries\n",
      "(II) processed 430000 entries\n",
      "(II) processed 440000 entries\n",
      "(II) processed 450000 entries\n",
      "(II) processed 460000 entries\n",
      "(II) processed 470000 entries\n",
      "(II) processed 480000 entries\n",
      "(II) processed 490000 entries\n",
      "(II) processed 500000 entries\n",
      "(II) processed 510000 entries\n",
      "(II) processed 520000 entries\n",
      "(II) processed 530000 entries\n",
      "(II) processed 540000 entries\n",
      "(II) processed 550000 entries\n",
      "Include dump dump_webservice_azure.json ...\n",
      "Iterate over ../dumps/dump_webservice_azure.json ...\n",
      "(I)  processed 10000 entries\n",
      "(I)  processed 20000 entries\n",
      "(I)  processed 30000 entries\n",
      "(I)  processed 40000 entries\n",
      "(I)  processed 50000 entries\n",
      "(I)  processed 60000 entries\n",
      "(I)  processed 70000 entries\n",
      "(I)  processed 80000 entries\n",
      "(I)  processed 90000 entries\n",
      "(I)  processed 100000 entries\n",
      "(I)  processed 110000 entries\n",
      "(I)  processed 120000 entries\n",
      "(I)  processed 130000 entries\n",
      "(I)  processed 140000 entries\n",
      "(I)  processed 150000 entries\n",
      "(I)  processed 160000 entries\n",
      "(I)  processed 170000 entries\n",
      "(I)  processed 180000 entries\n",
      "(I)  processed 190000 entries\n",
      "(I)  processed 200000 entries\n",
      "(I)  processed 210000 entries\n",
      "(I)  processed 220000 entries\n",
      "(I)  processed 230000 entries\n",
      "(I)  processed 240000 entries\n",
      "(I)  processed 250000 entries\n",
      "(I)  processed 260000 entries\n",
      "(I)  processed 270000 entries\n",
      "(I)  processed 280000 entries\n",
      "(I)  processed 290000 entries\n",
      "(I)  processed 300000 entries\n",
      "(I)  processed 310000 entries\n",
      "(I)  processed 320000 entries\n",
      "(I)  processed 330000 entries\n",
      "(I)  processed 340000 entries\n",
      "(I)  processed 350000 entries\n",
      "(I)  processed 360000 entries\n",
      "(I)  processed 370000 entries\n",
      "(I)  processed 380000 entries\n",
      "(I)  processed 390000 entries\n",
      "(I)  processed 400000 entries\n",
      "(I)  processed 410000 entries\n",
      "(I)  processed 420000 entries\n",
      "(I)  processed 430000 entries\n",
      "(I)  processed 440000 entries\n",
      "(I)  processed 450000 entries\n",
      "(I)  processed 460000 entries\n",
      "(I)  processed 470000 entries\n",
      "(I)  processed 480000 entries\n",
      "(I)  processed 490000 entries\n",
      "(I)  processed 500000 entries\n",
      "(I)  processed 510000 entries\n",
      "(I)  processed 520000 entries\n",
      "(I)  processed 530000 entries\n",
      "Iterate over ../dumps/dump_webservice_azure.json ...\n",
      "(II) processed 10000 entries\n",
      "(II) processed 20000 entries\n",
      "(II) processed 30000 entries\n",
      "(II) processed 40000 entries\n",
      "(II) processed 50000 entries\n",
      "(II) processed 60000 entries\n",
      "(II) processed 70000 entries\n",
      "(II) processed 80000 entries\n",
      "(II) processed 90000 entries\n",
      "(II) processed 100000 entries\n",
      "(II) processed 110000 entries\n",
      "(II) processed 120000 entries\n",
      "(II) processed 130000 entries\n",
      "(II) processed 140000 entries\n",
      "(II) processed 150000 entries\n",
      "(II) processed 160000 entries\n",
      "(II) processed 170000 entries\n",
      "(II) processed 180000 entries\n",
      "(II) processed 190000 entries\n",
      "(II) processed 200000 entries\n",
      "(II) processed 210000 entries\n",
      "(II) processed 220000 entries\n",
      "(II) processed 230000 entries\n",
      "(II) processed 240000 entries\n",
      "(II) processed 250000 entries\n",
      "(II) processed 260000 entries\n",
      "(II) processed 270000 entries\n",
      "(II) processed 280000 entries\n",
      "(II) processed 290000 entries\n",
      "(II) processed 300000 entries\n",
      "(II) processed 310000 entries\n",
      "(II) processed 320000 entries\n",
      "(II) processed 330000 entries\n",
      "(II) processed 340000 entries\n",
      "(II) processed 350000 entries\n",
      "(II) processed 360000 entries\n",
      "(II) processed 370000 entries\n",
      "(II) processed 380000 entries\n",
      "(II) processed 390000 entries\n",
      "(II) processed 400000 entries\n",
      "(II) processed 410000 entries\n",
      "(II) processed 420000 entries\n",
      "(II) processed 430000 entries\n",
      "(II) processed 440000 entries\n",
      "(II) processed 450000 entries\n",
      "(II) processed 460000 entries\n",
      "(II) processed 470000 entries\n",
      "(II) processed 480000 entries\n",
      "(II) processed 490000 entries\n",
      "(II) processed 500000 entries\n",
      "(II) processed 510000 entries\n",
      "(II) processed 520000 entries\n",
      "(II) processed 530000 entries\n",
      "negative network duration for context dkc3vnme\n",
      "negative network duration for context 9cu71ij9\n",
      "zero database duration for context ir0x2yem\n",
      "zero computing duration for context abaijyzh\n",
      "zero database duration for context xy3fh97e\n",
      "zero computing duration for context de86htl9\n",
      "negative computing duration for context iilkwc1o\n",
      "zero database duration for context gks8eibz\n",
      "zero computing duration for context kg4v2hs4\n",
      "negative network duration for context vjc66xc1\n",
      "negative network duration for context eda865vi\n",
      "negative network duration for context pu7m8dab\n",
      "zero computing duration for context pjiwv0a0\n",
      "zero database duration for context 7ckmopr1\n",
      "zero database duration for context 58a44pv6\n",
      "zero database duration for context 2zwid57o\n",
      "zero computing duration for context i2vvbrvq\n",
      "zero computing duration for context kpdftxt4\n",
      "zero database duration for context 1dzxsljg\n",
      "zero database duration for context stetdduk\n",
      "negative computing duration for context f32ujntv\n",
      "zero database duration for context qhnezxvf\n",
      "zero database duration for context oysrhpyr\n"
     ]
    }
   ],
   "source": [
    "plotdata = []\n",
    "\n",
    "for dump in logdumps:\n",
    "    print(f\"Include dump {dump} ...\")\n",
    "    # Count entries to get some progress feedback\n",
    "    entries = 0\n",
    "    contexts = {}\n",
    "    otherUserAgentContextList = []\n",
    "    relevantContextList = []\n",
    "\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(I)  processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        if isinstance(logentry, le.RequestLog):\n",
    "            userAgent = logentry.event['request']['headers']['user-agent']\n",
    "            if not str(userAgent).startswith(\"node-fetch\") | str(userAgent).startswith(\"Artillery\"):\n",
    "                print(f\"Other user agent, will filter: {userAgent}\")\n",
    "                otherUserAgentContextList.append(logentry.context_id)\n",
    "\n",
    "        if logentry.function == \"addcartitem\" and not (logentry.context_id in relevantContextList):\n",
    "            relevantContextList.append(logentry.context_id)\n",
    "\n",
    "    # Init stats for dump\n",
    "    entries = 0\n",
    "    measurements = {}\n",
    "\n",
    "\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(II) processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        id = logentry.context_id\n",
    "        if isinstance(logentry, le.PerfLog) and id in relevantContextList:\n",
    "            context_ok = True\n",
    "            fnName = logentry.function\n",
    "            if fnName == \"addcartitem\" or fnName == \"cartkvstorage\":\n",
    "                if id in otherUserAgentContextList:\n",
    "                    context_ok = False\n",
    "                    print(f\"context filter applied to context {id}\")\n",
    "\n",
    "                if context_ok:\n",
    "                    # Create context if there isn't one\n",
    "                    if not (id in contexts):\n",
    "                        contexts[id] = []\n",
    "                        measurements[id] = {}\n",
    "                        measurements[id][\"compute\"] = 0.0\n",
    "                        measurements[id][\"network\"] = 0.0\n",
    "                        measurements[id][\"db\"] = 0.0\n",
    "                        measurements[id][\"op_cpu\"] = 0\n",
    "                        measurements[id][\"op_nw\"] = 0\n",
    "                        measurements[id][\"op_db\"] = 0\n",
    "\n",
    "                    # Check if there is already the same entry for this context (duplicate)\n",
    "                    for checkEntry in contexts[id]:\n",
    "                        if str(checkEntry) == str(entry):\n",
    "                            # duplicate -> do not evaluate\n",
    "                            context_ok = False\n",
    "                            break\n",
    "\n",
    "                if context_ok and logentry.type == \"measure\":\n",
    "                    # context is ok => add to context list and add to stats\n",
    "                    contexts[id].append(entry)\n",
    "\n",
    "                    duration = logentry.perf[\"duration\"]\n",
    "                    if duration < 0:\n",
    "                        print(f\"ERROR: negative duration for entry {entry}\")\n",
    "\n",
    "                    plattform = logentry.platform\n",
    "\n",
    "\n",
    "                    if logentry.perf_type[1] == \"rpcIn\":\n",
    "                        #Type is complete (inner function) call (but not the root one) (e.g., D or E)\n",
    "                        measurements[id][\"compute\"] += duration\n",
    "                        measurements[id][\"op_cpu\"] += 1\n",
    "\n",
    "                        if fnName != \"addcartitem\":\n",
    "                            # not a root call\n",
    "                            measurements[id][\"network\"] -= duration\n",
    "                            measurements[id][\"op_nw\"] += 1\n",
    "\n",
    "                    elif logentry.perf_type[1] == \"rpcOut\":\n",
    "                        # Type is partcall (e.g., B or C)\n",
    "                        measurements[id][\"compute\"] -= duration\n",
    "                        measurements[id][\"network\"] += duration\n",
    "                        measurements[id][\"op_cpu\"] += 1\n",
    "                        measurements[id][\"op_nw\"] += 1\n",
    "                    elif logentry.perf_type[1] == \"dbOut\":\n",
    "                        #type is DB call (e.g., F)\n",
    "                        measurements[id][\"compute\"] -= duration\n",
    "                        measurements[id][\"db\"] += duration\n",
    "                        measurements[id][\"op_cpu\"] += 1\n",
    "                        measurements[id][\"op_db\"] += 1\n",
    "                    else:\n",
    "                        # type is something else -> Print\n",
    "                        print(\"unhandled type, pls check:\")\n",
    "                        for perfType in logentry.perf_type:\n",
    "                            print(f\"type is {perfType}\")\n",
    "\n",
    "    # Write measurements in plotdata\n",
    "    for ctx_id in measurements:\n",
    "        if measurements[ctx_id][\"compute\"] < 0:\n",
    "            print(f\"negative computing duration for context {ctx_id}\")\n",
    "            continue\n",
    "        if measurements[ctx_id][\"network\"] < 0:\n",
    "            print(f\"negative network duration for context {ctx_id}\")\n",
    "            continue\n",
    "        if measurements[ctx_id][\"db\"] < 0:\n",
    "            print(f\"negative database duration for context {ctx_id}\")\n",
    "            continue\n",
    "\n",
    "        if measurements[ctx_id][\"compute\"] == 0:\n",
    "            print(f\"zero computing duration for context {ctx_id}\")\n",
    "            continue\n",
    "        if measurements[ctx_id][\"network\"] == 0:\n",
    "            print(f\"zero network duration for context {ctx_id}\")\n",
    "            continue\n",
    "        if measurements[ctx_id][\"db\"] == 0:\n",
    "            print(f\"zero database duration for context {ctx_id}\")\n",
    "            continue\n",
    "\n",
    "        row = {}\n",
    "        row[\"id\"] = ctx_id\n",
    "        row[\"plattform\"] = plattform\n",
    "        row[\"class\"] = \"compute\"\n",
    "        row[\"ops\"] = measurements[ctx_id][\"op_cpu\"]\n",
    "        row[\"duration\"] = measurements[ctx_id][\"compute\"]\n",
    "        plotdata.append(row)\n",
    "\n",
    "        row = {}\n",
    "        row[\"id\"] = ctx_id\n",
    "        row[\"plattform\"] = plattform\n",
    "        row[\"class\"] = \"network\"\n",
    "        row[\"ops\"] = measurements[ctx_id][\"op_nw\"]\n",
    "        row[\"duration\"] = measurements[ctx_id][\"network\"]\n",
    "        plotdata.append(row)\n",
    "\n",
    "        row = {}\n",
    "        row[\"id\"] = ctx_id\n",
    "        row[\"plattform\"] = plattform\n",
    "        row[\"class\"] = \"db\"\n",
    "        row[\"ops\"] = measurements[ctx_id][\"op_db\"]\n",
    "        row[\"duration\"] = measurements[ctx_id][\"db\"]\n",
    "        plotdata.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         id plattform    class  ops    duration\n0  hb3xgee6       aws  compute    5   19.962382\n1  hb3xgee6       aws  network    2  761.150395\n2  hb3xgee6       aws       db    2   56.966573\n3  3i251oth       aws  compute    5    3.664852\n4  3i251oth       aws  network    2  819.356427",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>plattform</th>\n      <th>class</th>\n      <th>ops</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hb3xgee6</td>\n      <td>aws</td>\n      <td>compute</td>\n      <td>5</td>\n      <td>19.962382</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hb3xgee6</td>\n      <td>aws</td>\n      <td>network</td>\n      <td>2</td>\n      <td>761.150395</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hb3xgee6</td>\n      <td>aws</td>\n      <td>db</td>\n      <td>2</td>\n      <td>56.966573</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3i251oth</td>\n      <td>aws</td>\n      <td>compute</td>\n      <td>5</td>\n      <td>3.664852</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3i251oth</td>\n      <td>aws</td>\n      <td>network</td>\n      <td>2</td>\n      <td>819.356427</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.DataFrame(plotdata)\n",
    "df_calls.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_calls.to_pickle(oufile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}