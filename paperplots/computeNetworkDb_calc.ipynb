{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import befaas.logentry as le\n",
    "from befaas.fileutil import log_entry_iterator\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "logdumps = [\"dump_webservice_aws_small.json\"]\n",
    "#logdumps = [\"dump_webservice_aws_23.json\",\"dump_webservice_google_23.json\",\"dump_webservice_azure_23.json\"]\n",
    "oufile = \"../img/computeNetworkDbEcomm.pkl\"\n",
    "\n",
    "print(\"Everything is set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump dump_webservice_aws_small.json ...\n",
      "Iterate over ../dumps/dump_webservice_aws_small.json ...\n",
      "(I)  processed 10000 entries\n",
      "(I)  processed 20000 entries\n",
      "(I)  processed 30000 entries\n",
      "(I)  processed 40000 entries\n",
      "(I)  processed 50000 entries\n",
      "(I)  processed 60000 entries\n",
      "Iterate over ../dumps/dump_webservice_aws_small.json ...\n",
      "(II) processed 10000 entries\n",
      "(II) processed 20000 entries\n",
      "(II) processed 30000 entries\n",
      "(II) processed 40000 entries\n",
      "(II) processed 50000 entries\n",
      "(II) processed 60000 entries\n"
     ]
    }
   ],
   "source": [
    "plotdata = []\n",
    "\n",
    "for dump in logdumps:\n",
    "    print(f\"Include dump {dump} ...\")\n",
    "    # Count entries to get some progress feedback\n",
    "    entries = 0\n",
    "    contexts = {}\n",
    "    otherUserAgentContextList = []\n",
    "    relevantContextList = []\n",
    "\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(I)  processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        if isinstance(logentry, le.RequestLog):\n",
    "            userAgent = logentry.event['request']['headers']['user-agent']\n",
    "            if not str(userAgent).startswith(\"node-fetch\") | str(userAgent).startswith(\"Artillery\"):\n",
    "                print(f\"Other user agent, will filter: {userAgent}\")\n",
    "                otherUserAgentContextList.append(logentry.context_id)\n",
    "\n",
    "        if logentry.function == \"addcartitem\" and not (logentry.context_id in relevantContextList):\n",
    "            relevantContextList.append(logentry.context_id)\n",
    "\n",
    "    # Init stats for dump\n",
    "    entries = 0\n",
    "    measurements = {}\n",
    "\n",
    "\n",
    "    for entry in log_entry_iterator(filepath + dump):\n",
    "        entries = entries + 1\n",
    "        if (entries % 10000 == 0):\n",
    "            print(f\"(II) processed {entries} entries\")\n",
    "\n",
    "        logentry = le.cast_log_type(entry)\n",
    "        id = logentry.context_id\n",
    "        if isinstance(logentry, le.PerfLog) and id in relevantContextList:\n",
    "            context_ok = True\n",
    "            fnName = logentry.function\n",
    "            if fnName == \"addcartitem\" or fnName == \"cartkvstorage\":\n",
    "                if id in otherUserAgentContextList:\n",
    "                    context_ok = False\n",
    "                    print(f\"context filter applied to context {id}\")\n",
    "\n",
    "                if context_ok:\n",
    "                    # Create context if there isn't one\n",
    "                    if not (id in contexts):\n",
    "                        contexts[id] = []\n",
    "                        measurements[id] = {}\n",
    "                        measurements[id][\"compute\"] = 0.0\n",
    "                        measurements[id][\"network\"] = 0.0\n",
    "                        measurements[id][\"db\"] = 0.0\n",
    "                        measurements[id][\"op_cpu\"] = 0\n",
    "                        measurements[id][\"op_nw\"] = 0\n",
    "                        measurements[id][\"op_db\"] = 0\n",
    "\n",
    "                    # Check if there is already the same entry for this context (duplicate)\n",
    "                    for checkEntry in contexts[id]:\n",
    "                        if str(checkEntry) == str(entry):\n",
    "                            # duplicate -> do not evaluate\n",
    "                            context_ok = False\n",
    "                            break\n",
    "\n",
    "                if context_ok and logentry.type == \"measure\":\n",
    "                    # context is ok => add to context list and add to stats\n",
    "                    contexts[id].append(entry)\n",
    "\n",
    "                    duration = logentry.perf[\"duration\"]\n",
    "                    if duration < 0:\n",
    "                        print(f\"ERROR: negative duration for entry {entry}\")\n",
    "\n",
    "                    plattform = logentry.platform\n",
    "\n",
    "\n",
    "                    if logentry.perf_type[1] == \"rpcIn\":\n",
    "                        #Type is complete (inner function) call (but not the root one) (e.g., D or E)\n",
    "                        measurements[id][\"compute\"] += duration\n",
    "                        measurements[id][\"op_cpu\"] += 1\n",
    "\n",
    "                        if fnName != \"addcartitem\":\n",
    "                            # not a root call\n",
    "                            measurements[id][\"network\"] -= duration\n",
    "                            measurements[id][\"op_nw\"] += 1\n",
    "\n",
    "                    elif logentry.perf_type[1] == \"rpcOut\":\n",
    "                        # Type is partcall (e.g., B or C)\n",
    "                        measurements[id][\"compute\"] -= duration\n",
    "                        measurements[id][\"network\"] += duration\n",
    "                        measurements[id][\"op_cpu\"] += 1\n",
    "                        measurements[id][\"op_nw\"] += 1\n",
    "                    elif logentry.perf_type[1] == \"dbOut\":\n",
    "                        #type is DB call (e.g., F)\n",
    "                        measurements[id][\"compute\"] -= duration\n",
    "                        measurements[id][\"db\"] += duration\n",
    "                        measurements[id][\"op_cpu\"] += 1\n",
    "                        measurements[id][\"op_db\"] += 1\n",
    "                    else:\n",
    "                        # type is something else -> Print\n",
    "                        print(\"unhandled type, pls check:\")\n",
    "                        for perfType in logentry.perf_type:\n",
    "                            print(f\"type is {perfType}\")\n",
    "\n",
    "    # Write measurements in plotdata\n",
    "    for ctx_id in measurements:\n",
    "        if measurements[ctx_id][\"compute\"] < 0:\n",
    "            print(f\"negative computing duration for context {ctx_id}\")\n",
    "            continue\n",
    "        if measurements[ctx_id][\"network\"] < 0:\n",
    "            print(f\"negative network duration for context {ctx_id}\")\n",
    "            continue\n",
    "        if measurements[ctx_id][\"db\"] < 0:\n",
    "            print(f\"negative database duration for context {ctx_id}\")\n",
    "            continue\n",
    "\n",
    "        row = {}\n",
    "        row[\"id\"] = ctx_id\n",
    "        row[\"plattform\"] = plattform\n",
    "        row[\"class\"] = \"compute\"\n",
    "        row[\"ops\"] = measurements[ctx_id][\"op_cpu\"]\n",
    "        row[\"duration\"] = measurements[ctx_id][\"compute\"]\n",
    "        plotdata.append(row)\n",
    "\n",
    "        row = {}\n",
    "        row[\"id\"] = ctx_id\n",
    "        row[\"plattform\"] = plattform\n",
    "        row[\"class\"] = \"network\"\n",
    "        row[\"ops\"] = measurements[ctx_id][\"op_nw\"]\n",
    "        row[\"duration\"] = measurements[ctx_id][\"network\"]\n",
    "        plotdata.append(row)\n",
    "\n",
    "        row = {}\n",
    "        row[\"id\"] = ctx_id\n",
    "        row[\"plattform\"] = plattform\n",
    "        row[\"class\"] = \"db\"\n",
    "        row[\"ops\"] = measurements[ctx_id][\"op_db\"]\n",
    "        row[\"duration\"] = measurements[ctx_id][\"db\"]\n",
    "        plotdata.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         id plattform    class  ops    duration\n0  5qawkj42       aws  compute    5   63.916805\n1  5qawkj42       aws  network    2  871.863165\n2  5qawkj42       aws       db    2   40.919689\n3  g40la22n       aws  compute    5   16.052964\n4  g40la22n       aws  network    2  966.032307",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>plattform</th>\n      <th>class</th>\n      <th>ops</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5qawkj42</td>\n      <td>aws</td>\n      <td>compute</td>\n      <td>5</td>\n      <td>63.916805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5qawkj42</td>\n      <td>aws</td>\n      <td>network</td>\n      <td>2</td>\n      <td>871.863165</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5qawkj42</td>\n      <td>aws</td>\n      <td>db</td>\n      <td>2</td>\n      <td>40.919689</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>g40la22n</td>\n      <td>aws</td>\n      <td>compute</td>\n      <td>5</td>\n      <td>16.052964</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>g40la22n</td>\n      <td>aws</td>\n      <td>network</td>\n      <td>2</td>\n      <td>966.032307</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.DataFrame(plotdata)\n",
    "df_calls.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_calls.to_pickle(oufile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}