{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json_coder\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import befaas as bf\n",
    "import befaas.logentry as le\n",
    "from befaas.graph import build_function_graph, add_default_metadata, conv_to_ms\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "#logdumps = [\"dump_streaming_google.json\",\"dump_streaming_aws.json\",\"dump_streaming_azure.json\"]\n",
    "#logdumps = [\"dump_streaming_google.json\",\"dump_streaming_aws.json\"]\n",
    "logdumps = [\"dump_streaming_aws.json\"]\n",
    "#logdumps = [\"dump_streaming_azure.json\"]\n",
    "outfile = \"../img/2023_streaming_coldStarts.pkl\"\n",
    "plotdata = []\n",
    "\n",
    "print(\"Everything is set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump dump_streaming_google.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts and find cold starts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Analyze cold starts...\n",
      "Done.\n",
      "Include dump dump_streaming_aws.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts and find cold starts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Analyze cold starts...\n",
      "Done.\n",
      "Include dump dump_streaming_azure.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts and find cold starts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Analyze cold starts...\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"addVideo\", \"kind\": \"coldstart\", \"start\": 6830, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"authDevice\", \"kind\": \"coldstart\", \"start\": 6830, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"getUserMeta\", \"kind\": \"coldstart\", \"start\": 6830, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"getVideos\", \"kind\": \"coldstart\", \"start\": 6830, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"patchUserMeta\", \"kind\": \"coldstart\", \"start\": 6830, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"registerDevice\", \"kind\": \"coldstart\", \"start\": 6830, \"latency\": 0}\n",
      "Error: {\"Provider\": \"azure\", \"function\": \"registerUser\", \"kind\": \"coldstart\", \"start\": 6831, \"latency\": 0}\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debugpairs = []\n",
    "for dump in logdumps:\n",
    "    print(f\"Include dump {dump} ...\")\n",
    "    print(\"Load dump... (may take a while)\")\n",
    "    data = bf.load_logs(filepath + dump)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    print(\"Sort data to contexts and find cold starts...\")\n",
    "    contexts = {}\n",
    "    coldtsarts = []\n",
    "    experimentStart = None\n",
    "\n",
    "    for entry in data:\n",
    "        id = entry.context_id\n",
    "        if id == None:\n",
    "            if isinstance(entry, le.ColdstartLog):\n",
    "                coldtsarts.append(entry)\n",
    "            else:\n",
    "                print(\"Some other log entry type\")\n",
    "\n",
    "        if not id == None:\n",
    "            if not (id in contexts):\n",
    "                contexts[id] = []\n",
    "\n",
    "            contexts[id].append(entry)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    print(\"Find xpairs...\")\n",
    "    xpairs = {}\n",
    "\n",
    "    for ctx_id in contexts:\n",
    "        ctx = contexts[ctx_id]\n",
    "        for entry in ctx:\n",
    "            id = entry.event[\"xPair\"]\n",
    "            if not (id in xpairs):\n",
    "                xpairs[id] = []\n",
    "\n",
    "            specialPair = False\n",
    "            if isinstance(entry, le.PerfLog):\n",
    "                if not entry.perf_type_data == \"\":\n",
    "                    parts = entry.perf_type_data.split(\":\")\n",
    "                    if len(parts) > 1:\n",
    "                        id = parts[1]\n",
    "                        if not (id in xpairs):\n",
    "                            xpairs[id] = []\n",
    "                        xpairs[id].append(entry)\n",
    "                        specialPair = True\n",
    "\n",
    "            if not specialPair:\n",
    "                xpairs[id].append(entry)\n",
    "    print(\"done.\")\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for xpairID in xpairs:\n",
    "        xpair = xpairs[xpairID]\n",
    "        for entry in xpair:\n",
    "            if isinstance(entry, le.ArtilleryLog):\n",
    "                if experimentStart == None:\n",
    "                    experimentStart = entry.timestamp\n",
    "                if entry.timestamp < experimentStart:\n",
    "                    experimentStart = entry.timestamp\n",
    "\n",
    "    for xpairID in xpairs:\n",
    "        xpair = xpairs[xpairID]\n",
    "\n",
    "        requestStart = None\n",
    "        requestEnd = None\n",
    "        function = \"\"\n",
    "        platform = \"\"\n",
    "\n",
    "        if len(xpair) == 2:\n",
    "            if str(xpair[0].url).__contains__(\"azure\"):\n",
    "                continue\n",
    "                for entry in xpair:\n",
    "                    if isinstance(entry, le.ArtilleryLog):\n",
    "                        if entry.type == \"before\":\n",
    "                           requestStart = entry.timestamp\n",
    "                        if entry.type == \"after\":\n",
    "                           requestEnd = entry.timestamp\n",
    "                           function = str(entry.url).split(\"/\")[-1]\n",
    "                           platform = \"azure\"\n",
    "            else:\n",
    "                print(\"Error for \" + xpair[0].url)\n",
    "        else:\n",
    "            for entry in xpair:\n",
    "                if isinstance(entry, le.ArtilleryLog):\n",
    "                    if entry.type == \"before\":\n",
    "                       requestStart = entry.timestamp\n",
    "                    if entry.type == \"after\":\n",
    "                       requestEnd = entry.timestamp\n",
    "                if isinstance(entry, le.RequestLog):\n",
    "                    function = entry.function\n",
    "                    platform = entry.platform\n",
    "\n",
    "        latency = (requestEnd - requestStart).microseconds / 1000\n",
    "\n",
    "        if not platform == \"\":\n",
    "            row = {}\n",
    "            row[\"Provider\"] = platform\n",
    "            row[\"function\"] = function\n",
    "            row[\"kind\"] = \"request\"\n",
    "            row[\"start\"] = (requestStart - experimentStart).seconds\n",
    "            row[\"latency\"] = latency\n",
    "\n",
    "            if row[\"start\"] == 0:\n",
    "                debugpairs.append(xpair)\n",
    "\n",
    "            if row[\"start\"] < 4000:\n",
    "                plotdata.append(row)\n",
    "            else:\n",
    "                print(\"Error: \" + json.dumps(row))\n",
    "        else:\n",
    "            debugpairs.append(xpair)\n",
    "\n",
    "    print(\"Analyze cold starts...\")\n",
    "\n",
    "    # Find experiment Start for Cloud platform and use cloud timestamp for this\n",
    "    experimentStart = None\n",
    "    for cold in coldtsarts:\n",
    "        if not cold.platform == \"artillery\":\n",
    "            # print(\"Start is \" + str(cold.timestamp))\n",
    "            if experimentStart == None:\n",
    "                    experimentStart = cold.timestamp\n",
    "            if cold.timestamp < experimentStart:\n",
    "                    experimentStart = cold.timestamp\n",
    "    for cold in coldtsarts:\n",
    "        if not cold.platform == \"artillery\":\n",
    "            row = {}\n",
    "            row[\"Provider\"] = cold.platform\n",
    "            row[\"function\"] = cold.function\n",
    "            row[\"kind\"] = \"coldstart\"\n",
    "            row[\"start\"] = (cold.timestamp - experimentStart).seconds\n",
    "            row[\"latency\"] = 0\n",
    "\n",
    "            if row[\"start\"] < 4000:\n",
    "                plotdata.append(row)\n",
    "            else:\n",
    "                print(\"Error: \" + json.dumps(row))\n",
    "                debugpairs.append(cold)\n",
    "\n",
    "\n",
    "    print(\"Done.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Provider        function     kind  start  latency\n",
      "0   google    registerUser  request      0    273.0\n",
      "1   google  registerDevice  request      0    231.0\n",
      "2   google  registerDevice  request      0     33.0\n",
      "3   google    registerUser  request      0     27.0\n",
      "4   google  registerDevice  request      0     34.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "              start       latency\ncount  40094.000000  40094.000000\nmean    1248.624408     40.864044\nstd      762.276470     40.673841\nmin        0.000000      0.000000\n25%      214.000000     24.000000\n50%     1683.000000     32.000000\n75%     1796.000000     46.000000\nmax     2208.000000    956.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>latency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>40094.000000</td>\n      <td>40094.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1248.624408</td>\n      <td>40.864044</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>762.276470</td>\n      <td>40.673841</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>214.000000</td>\n      <td>24.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1683.000000</td>\n      <td>32.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1796.000000</td>\n      <td>46.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2208.000000</td>\n      <td>956.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.DataFrame(plotdata)\n",
    "print(df_calls.head())\n",
    "df_calls.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_calls.to_pickle(outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}