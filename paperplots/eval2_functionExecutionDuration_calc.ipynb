{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is set up.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json_coder\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import befaas as bf\n",
    "import befaas.logentry as le\n",
    "from befaas.graph import build_function_graph, add_default_metadata, conv_to_ms\n",
    "\n",
    "filepath = \"../dumps/\"\n",
    "logdumps = [\"iot_aws_split.json\",\"iot_aws_edge.json\",\"iot_azure_split.json\", \"iot_azure_edge.json\", \"iot_google_split.json\", \"iot_google_edge.json\"]\n",
    "#logdumps = [\"iot_aws_split.json\",\"iot_aws_edge.json\"]\n",
    "#logdumps = [\"iot_aws_split.json\"]\n",
    "\n",
    "outfile = \"../img/functionRuntimesIoT.pkl\"\n",
    "plotdata = []\n",
    "\n",
    "print(\"Everything is set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include dump iot_aws_split.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Sum up function execution times...\n",
      "Include dump iot_aws_edge.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Sum up function execution times...\n",
      "Include dump iot_azure_split.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Sum up function execution times...\n",
      "Include dump iot_azure_edge.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Sum up function execution times...\n",
      "Include dump iot_google_split.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Sum up function execution times...\n",
      "Include dump iot_google_edge.json ...\n",
      "Load dump... (may take a while)\n",
      "Done.\n",
      "Sort data to contexts...\n",
      "Done.\n",
      "Find xpairs...\n",
      "done.\n",
      "Sum up function execution times...\n"
     ]
    }
   ],
   "source": [
    "for dump in logdumps:\n",
    "    print(f\"Include dump {dump} ...\")\n",
    "\n",
    "    platform = dump.split(\"_\")[1]\n",
    "    setup = dump.split(\"_\")[2].split(\".\")[0]\n",
    "\n",
    "    print(\"Load dump... (may take a while)\")\n",
    "    data = bf.load_logs(filepath + dump)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    print(\"Sort data to contexts...\")\n",
    "    contexts = {}\n",
    "\n",
    "    for entry in data:\n",
    "        id = entry.context_id\n",
    "        if id == None:\n",
    "            continue\n",
    "\n",
    "        if not (id in contexts):\n",
    "            contexts[id] = []\n",
    "\n",
    "        contexts[id].append(entry)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    print(\"Find xpairs...\")\n",
    "    xpairs = {}\n",
    "\n",
    "    for ctx_id in contexts:\n",
    "        ctx = contexts[ctx_id]\n",
    "        for entry in ctx:\n",
    "            id = entry.event[\"xPair\"]\n",
    "            if not (id in xpairs):\n",
    "                xpairs[id] = []\n",
    "\n",
    "            specialPair = False\n",
    "            if isinstance(entry, le.PerfLog):\n",
    "                if not entry.perf_type_data == \"\":\n",
    "                    parts = entry.perf_type_data.split(\":\")\n",
    "                    if len(parts) > 1:\n",
    "                        id = parts[1]\n",
    "                        if not (id in xpairs):\n",
    "                            xpairs[id] = []\n",
    "                        xpairs[id].append(entry)\n",
    "                        specialPair = True\n",
    "\n",
    "            if not specialPair:\n",
    "                xpairs[id].append(entry)\n",
    "    print(\"done.\")\n",
    "\n",
    "    print(\"Sum up function execution times...\")\n",
    "    computeSum = 0\n",
    "    networkSum = 0\n",
    "    databaseSum = 0\n",
    "    debugpairs = []\n",
    "\n",
    "    for xpairID in xpairs:\n",
    "        xpair = xpairs[xpairID]\n",
    "\n",
    "        for entry in xpair:\n",
    "                if isinstance(entry, le.PerfLog):\n",
    "                    if entry.type == \"measure\":\n",
    "                        if entry.perf_type[1] == \"post\":\n",
    "                            computeSum = computeSum + entry.perf[\"duration\"]\n",
    "                        if entry.perf_type[1] == \"rpcIn\":\n",
    "                            computeSum = computeSum + entry.perf[\"duration\"]\n",
    "                        if entry.perf_type[1] == \"msg\":\n",
    "                            computeSum = computeSum + entry.perf[\"duration\"]\n",
    "                        if entry.perf_type[1] == \"rpcOut\":\n",
    "                            networkSum = networkSum + entry.perf[\"duration\"]\n",
    "                            computeSum = computeSum - entry.perf[\"duration\"]\n",
    "                        if entry.perf_type[1] == \"dbOut\":\n",
    "                            databaseSum = databaseSum + entry.perf[\"duration\"]\n",
    "                            computeSum = computeSum - entry.perf[\"duration\"]\n",
    "\n",
    "    # print(str(executionDurationSum) + \" ms; \" + str (networkLatencySum) + \" ms; \"  + str (databaseDurationSum) + \" ms\")\n",
    "    # print(str(executionDurationSum/1000) + \" s; \" + str (networkLatencySum/1000) + \" s; \"  + str (databaseDurationSum/1000) + \" s\")\n",
    "    # print(str(executionDurationSum/1000/60) + \" min; \" + str (networkLatencySum/1000/60) + \" min; \"  + str (databaseDurationSum/1000/60) + \" min\")\n",
    "\n",
    "    row = {}\n",
    "    row[\"platform\"] = platform\n",
    "    row[\"setup\"] = setup\n",
    "    row[\"kind\"] = \"a_database\"\n",
    "    row[\"value\"] = databaseSum/1000\n",
    "    row[\"valuec\"] = databaseSum/1000\n",
    "    plotdata.append(row)\n",
    "\n",
    "    row = {}\n",
    "    row[\"platform\"] = platform\n",
    "    row[\"setup\"] = setup\n",
    "    row[\"kind\"] = \"b_compute\"\n",
    "    row[\"value\"] = computeSum/1000\n",
    "    row[\"valuec\"] = computeSum/1000 + databaseSum/1000\n",
    "    plotdata.append(row)\n",
    "\n",
    "    row = {}\n",
    "    row[\"platform\"] = platform\n",
    "    row[\"setup\"] = setup\n",
    "    row[\"kind\"] = \"c_network\"\n",
    "    row[\"value\"] = networkSum/1000\n",
    "    row[\"valuec\"] = networkSum/1000 + computeSum/1000 + databaseSum/1000\n",
    "    plotdata.append(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "             value       valuec\ncount    18.000000    18.000000\nmean    655.666349   963.773852\nstd     444.022642   790.884097\nmin      27.680618    27.680618\n25%     163.600788   163.600788\n50%     697.469568   823.436466\n75%    1079.321584  1891.943873\nmax    1249.620576  2044.879809",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>value</th>\n      <th>valuec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>18.000000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>655.666349</td>\n      <td>963.773852</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>444.022642</td>\n      <td>790.884097</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>27.680618</td>\n      <td>27.680618</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>163.600788</td>\n      <td>163.600788</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>697.469568</td>\n      <td>823.436466</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1079.321584</td>\n      <td>1891.943873</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1249.620576</td>\n      <td>2044.879809</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.DataFrame(plotdata)\n",
    "df_calls.head()\n",
    "df_calls.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_calls.to_pickle(outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}